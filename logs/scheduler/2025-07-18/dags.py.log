[2025-07-18T20:37:25.878+0000] {processor.py:186} INFO - Started process (PID=56) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:37:25.878+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:37:25.880+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:37:25.880+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:37:25.956+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:37:26.074+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:37:26.070+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:37:26.075+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:37:26.087+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.213 seconds
[2025-07-18T20:37:56.812+0000] {processor.py:186} INFO - Started process (PID=80) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:37:56.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:37:56.814+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:37:56.814+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:37:56.863+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:37:56.981+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:37:56.974+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:37:56.984+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:37:57.014+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.206 seconds
[2025-07-18T20:38:27.601+0000] {processor.py:186} INFO - Started process (PID=104) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:38:27.602+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:38:27.605+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:38:27.604+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:38:27.652+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:38:27.784+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:38:27.766+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:38:27.788+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:38:27.823+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.225 seconds
[2025-07-18T20:38:58.064+0000] {processor.py:186} INFO - Started process (PID=128) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:38:58.065+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:38:58.066+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:38:58.066+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:38:58.121+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:38:58.256+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:38:58.235+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:38:58.261+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:38:58.284+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.224 seconds
[2025-07-18T20:39:28.996+0000] {processor.py:186} INFO - Started process (PID=151) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:39:28.997+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:39:28.998+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:39:28.998+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:39:29.051+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:39:29.166+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:39:29.163+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:39:29.167+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:39:29.190+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.198 seconds
[2025-07-18T20:39:59.349+0000] {processor.py:186} INFO - Started process (PID=174) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:39:59.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:39:59.352+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:39:59.352+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:39:59.405+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:39:59.520+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:39:59.517+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:39:59.521+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:39:59.537+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.193 seconds
[2025-07-18T20:40:29.627+0000] {processor.py:186} INFO - Started process (PID=198) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:40:29.628+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:40:29.629+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:40:29.629+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:40:29.678+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:40:29.793+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:40:29.790+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:40:29.793+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:40:29.815+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.193 seconds
[2025-07-18T20:40:59.885+0000] {processor.py:186} INFO - Started process (PID=222) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:40:59.886+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:40:59.888+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:40:59.888+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:40:59.941+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:41:00.060+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:41:00.054+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:41:00.062+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:41:00.178+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.297 seconds
[2025-07-18T20:41:31.074+0000] {processor.py:186} INFO - Started process (PID=247) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:41:31.074+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:41:31.076+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:41:31.076+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:41:31.264+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:41:31.382+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:41:31.379+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:41:31.383+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:41:31.406+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.335 seconds
[2025-07-18T20:42:02.331+0000] {processor.py:186} INFO - Started process (PID=271) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:42:02.332+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:42:02.333+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:42:02.333+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:42:02.533+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:42:02.657+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:42:02.649+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:42:02.658+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:42:02.670+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.343 seconds
[2025-07-18T20:42:32.743+0000] {processor.py:186} INFO - Started process (PID=294) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:42:32.743+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:42:32.745+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:42:32.745+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:42:32.923+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:42:33.039+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:42:33.037+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:42:33.040+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:42:33.061+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.323 seconds
[2025-07-18T20:43:03.167+0000] {processor.py:186} INFO - Started process (PID=318) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:43:03.168+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:43:03.170+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:43:03.169+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:43:03.331+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:43:03.455+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:43:03.446+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:43:03.458+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:43:03.476+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.316 seconds
[2025-07-18T20:43:34.314+0000] {processor.py:186} INFO - Started process (PID=343) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:43:34.315+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:43:34.317+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:43:34.317+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:43:34.489+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:43:34.604+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:43:34.602+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:43:34.605+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:43:34.624+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.313 seconds
[2025-07-18T20:44:04.808+0000] {processor.py:186} INFO - Started process (PID=367) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:44:04.808+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:44:04.810+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:44:04.809+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:44:05.002+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:44:05.115+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:44:05.113+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:44:05.116+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:44:05.128+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.324 seconds
[2025-07-18T20:44:35.328+0000] {processor.py:186} INFO - Started process (PID=392) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:44:35.329+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:44:35.331+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:44:35.330+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:44:35.487+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:44:35.604+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:44:35.599+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:44:35.607+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:44:35.645+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.320 seconds
[2025-07-18T20:45:06.576+0000] {processor.py:186} INFO - Started process (PID=429) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:45:06.576+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:45:06.578+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:45:06.578+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:45:06.754+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:45:06.873+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:45:06.871+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:45:06.874+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:45:06.887+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.315 seconds
[2025-07-18T20:45:37.130+0000] {processor.py:186} INFO - Started process (PID=469) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:45:37.135+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:45:37.137+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:45:37.137+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:45:37.297+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:45:37.414+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:45:37.409+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:45:37.415+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:45:37.431+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.305 seconds
[2025-07-18T20:46:07.552+0000] {processor.py:186} INFO - Started process (PID=508) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:46:07.553+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:46:07.554+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:46:07.554+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:46:07.700+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:46:07.817+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:46:07.811+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:46:07.819+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:46:07.838+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.290 seconds
[2025-07-18T20:46:38.716+0000] {processor.py:186} INFO - Started process (PID=538) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:46:38.716+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:46:38.718+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:46:38.718+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:46:38.872+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:46:38.996+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:46:38.987+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:46:38.999+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:46:39.022+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.309 seconds
[2025-07-18T20:47:09.251+0000] {processor.py:186} INFO - Started process (PID=564) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:47:09.251+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:47:09.253+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:47:09.253+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:47:09.396+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:47:09.527+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:47:09.512+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:47:09.531+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:47:09.556+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.309 seconds
[2025-07-18T20:47:39.843+0000] {processor.py:186} INFO - Started process (PID=599) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:47:39.844+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:47:39.846+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:47:39.845+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:47:39.986+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:47:40.110+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:47:40.100+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:47:40.117+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:47:40.172+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.333 seconds
[2025-07-18T20:48:10.548+0000] {processor.py:186} INFO - Started process (PID=623) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:48:10.549+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:48:10.551+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:48:10.551+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:48:10.791+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:48:10.964+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:48:10.951+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:48:10.967+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:48:10.990+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.445 seconds
[2025-07-18T20:48:41.298+0000] {processor.py:186} INFO - Started process (PID=647) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:48:41.299+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:48:41.300+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:48:41.300+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:48:41.456+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:48:41.597+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:48:41.574+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:48:41.600+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:48:41.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.325 seconds
[2025-07-18T20:49:12.298+0000] {processor.py:186} INFO - Started process (PID=678) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:49:12.299+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:49:12.300+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:49:12.299+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:49:12.445+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:49:12.558+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:49:12.555+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:49:12.559+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:49:12.581+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.288 seconds
[2025-07-18T20:49:42.685+0000] {processor.py:186} INFO - Started process (PID=704) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:49:42.686+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:49:42.687+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:49:42.687+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:49:42.848+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:49:42.967+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:49:42.961+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:49:42.970+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:49:42.988+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.308 seconds
[2025-07-18T20:50:13.104+0000] {processor.py:186} INFO - Started process (PID=728) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:50:13.104+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:50:13.105+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:50:13.105+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:50:13.262+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:50:13.378+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:50:13.376+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:50:13.379+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:50:13.389+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.291 seconds
[2025-07-18T20:50:44.413+0000] {processor.py:186} INFO - Started process (PID=752) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:50:44.414+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:50:44.415+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:50:44.415+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:50:44.561+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:50:44.697+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:50:44.678+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:50:44.701+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:50:44.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.341 seconds
[2025-07-18T20:51:15.554+0000] {processor.py:186} INFO - Started process (PID=776) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:51:15.558+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:51:15.559+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:51:15.558+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:51:15.622+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:51:15.740+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:51:15.735+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:51:15.741+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:51:15.766+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.216 seconds
[2025-07-18T20:51:45.840+0000] {processor.py:186} INFO - Started process (PID=800) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:51:45.841+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:51:45.842+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:51:45.842+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:51:45.897+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:51:46.013+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:51:46.011+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:51:46.013+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:51:46.027+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.192 seconds
[2025-07-18T20:52:16.186+0000] {processor.py:186} INFO - Started process (PID=817) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:52:16.187+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:52:16.188+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:52:16.188+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:52:16.248+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:52:16.363+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:52:16.361+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:52:16.363+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:52:16.385+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.203 seconds
[2025-07-18T20:52:47.293+0000] {processor.py:186} INFO - Started process (PID=894) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:52:47.294+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:52:47.294+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:52:47.294+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:52:47.342+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:52:47.468+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:52:47.458+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:52:47.471+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:52:47.496+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.207 seconds
[2025-07-18T20:53:18.215+0000] {processor.py:186} INFO - Started process (PID=918) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:53:18.216+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:53:18.217+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:53:18.217+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:53:18.291+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:53:18.422+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:53:18.408+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:53:18.425+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:53:18.478+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.268 seconds
[2025-07-18T20:53:48.693+0000] {processor.py:186} INFO - Started process (PID=942) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:53:48.694+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:53:48.696+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:53:48.695+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:53:48.756+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:53:48.878+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:53:48.872+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:53:48.884+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:53:48.908+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.220 seconds
[2025-07-18T20:54:19.202+0000] {processor.py:186} INFO - Started process (PID=966) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:54:19.202+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:54:19.203+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:54:19.203+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:54:19.256+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:54:19.389+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:54:19.372+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:54:19.394+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:54:19.418+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.220 seconds
[2025-07-18T20:54:50.289+0000] {processor.py:186} INFO - Started process (PID=990) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:54:50.291+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:54:50.294+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:54:50.293+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:54:50.387+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:54:50.528+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:54:50.518+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:54:50.530+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:54:50.554+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.270 seconds
[2025-07-18T20:55:21.490+0000] {processor.py:186} INFO - Started process (PID=1014) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:55:21.491+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:55:21.493+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:55:21.492+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:55:21.553+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:55:21.679+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:55:21.669+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:55:21.682+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:55:21.704+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.219 seconds
[2025-07-18T20:55:52.611+0000] {processor.py:186} INFO - Started process (PID=1038) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:55:52.613+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:55:52.613+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:55:52.613+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:55:52.702+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:55:52.847+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:55:52.838+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:55:52.848+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:55:52.870+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.263 seconds
[2025-07-18T20:56:23.207+0000] {processor.py:186} INFO - Started process (PID=1070) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:56:23.208+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:56:23.208+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:56:23.208+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:56:23.263+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:56:23.399+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:56:23.378+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:56:23.404+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:56:23.434+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.231 seconds
[2025-07-18T20:56:54.177+0000] {processor.py:186} INFO - Started process (PID=1108) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:56:54.178+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:56:54.179+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:56:54.179+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:56:54.278+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:56:54.408+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:56:54.401+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:56:54.409+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:56:54.423+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.251 seconds
[2025-07-18T20:57:25.306+0000] {processor.py:186} INFO - Started process (PID=1146) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:57:25.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:57:25.308+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:57:25.307+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:57:25.358+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:57:25.478+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:57:25.469+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:57:25.479+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:57:25.494+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.191 seconds
[2025-07-18T20:57:56.211+0000] {processor.py:186} INFO - Started process (PID=1193) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:57:56.212+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:57:56.213+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:57:56.213+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:57:56.298+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:57:56.434+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:57:56.429+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:57:56.435+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:57:56.460+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.253 seconds
[2025-07-18T20:58:27.055+0000] {processor.py:186} INFO - Started process (PID=1235) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:58:27.056+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:58:27.057+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:58:27.057+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:58:27.106+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:58:27.230+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:58:27.218+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:58:27.231+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:58:27.252+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.201 seconds
[2025-07-18T20:58:57.407+0000] {processor.py:186} INFO - Started process (PID=1266) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:58:57.408+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:58:57.409+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:58:57.409+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:58:57.461+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:58:57.583+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:58:57.578+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:58:57.585+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:58:57.601+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.197 seconds
[2025-07-18T20:59:27.989+0000] {processor.py:186} INFO - Started process (PID=1301) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:59:27.990+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:59:27.991+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:59:27.990+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:59:28.061+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:59:28.176+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:59:28.172+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:59:28.177+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:59:28.201+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.216 seconds
[2025-07-18T20:59:58.440+0000] {processor.py:186} INFO - Started process (PID=1340) to work on /opt/airflow/dags/dags.py
[2025-07-18T20:59:58.440+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T20:59:58.441+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:59:58.441+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T20:59:58.492+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T20:59:58.624+0000] {logging_mixin.py:190} INFO - [2025-07-18T20:59:58.609+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T20:59:58.628+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T20:59:58.652+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.216 seconds
[2025-07-18T21:00:29.087+0000] {processor.py:186} INFO - Started process (PID=1381) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:00:29.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:00:29.089+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:00:29.088+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:00:29.138+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:00:29.264+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:00:29.253+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:00:29.267+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:00:29.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.210 seconds
[2025-07-18T21:00:59.530+0000] {processor.py:186} INFO - Started process (PID=1413) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:00:59.531+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:00:59.532+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:00:59.531+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:00:59.581+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:00:59.709+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:00:59.696+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:00:59.711+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:00:59.736+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.213 seconds
[2025-07-18T21:01:30.752+0000] {processor.py:186} INFO - Started process (PID=1441) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:01:30.753+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:01:30.753+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:01:30.753+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:01:30.804+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:01:30.933+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:01:30.920+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:01:30.940+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:01:30.966+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.217 seconds
[2025-07-18T21:02:01.006+0000] {processor.py:186} INFO - Started process (PID=1469) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:02:01.006+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:02:01.008+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:02:01.007+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:02:01.073+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:02:01.206+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:02:01.193+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:02:01.210+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:02:01.248+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.248 seconds
[2025-07-18T21:02:31.415+0000] {processor.py:186} INFO - Started process (PID=1499) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:02:31.416+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:02:31.418+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:02:31.417+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:02:31.477+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:02:31.615+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:02:31.594+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:02:31.622+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:02:31.650+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.241 seconds
[2025-07-18T21:03:02.386+0000] {processor.py:186} INFO - Started process (PID=1522) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:03:02.387+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:03:02.387+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:03:02.387+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:03:02.441+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:03:02.557+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:03:02.553+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:03:02.559+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:03:02.576+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.194 seconds
[2025-07-18T21:03:33.103+0000] {processor.py:186} INFO - Started process (PID=1545) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:03:33.103+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:03:33.104+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:03:33.104+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:03:33.157+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:03:33.283+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:03:33.273+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:03:33.286+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:03:33.302+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.204 seconds
[2025-07-18T21:04:03.802+0000] {processor.py:186} INFO - Started process (PID=1568) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:04:03.803+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:04:03.805+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:04:03.805+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:04:03.859+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:04:03.982+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:04:03.979+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:04:03.982+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:04:03.995+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.197 seconds
[2025-07-18T21:04:34.517+0000] {processor.py:186} INFO - Started process (PID=1591) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:04:34.518+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:04:34.519+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:04:34.519+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:04:34.571+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:04:34.699+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:04:34.686+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:04:34.702+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:04:34.716+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.203 seconds
[2025-07-18T21:05:05.212+0000] {processor.py:186} INFO - Started process (PID=1614) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:05:05.213+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:05:05.214+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:05:05.214+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:05:05.269+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:05:05.404+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:05:05.385+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:05:05.408+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:05:05.441+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.234 seconds
[2025-07-18T21:05:36.230+0000] {processor.py:186} INFO - Started process (PID=1637) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:05:36.231+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:05:36.232+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:05:36.231+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:05:36.280+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:05:36.416+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:05:36.395+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:05:36.420+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:05:36.449+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.223 seconds
[2025-07-18T21:06:07.159+0000] {processor.py:186} INFO - Started process (PID=1660) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:06:07.160+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:06:07.161+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:06:07.160+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:06:07.211+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:06:07.349+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:06:07.329+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:06:07.356+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:06:07.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.231 seconds
[2025-07-18T21:06:37.498+0000] {processor.py:186} INFO - Started process (PID=1683) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:06:37.498+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:06:37.499+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:06:37.499+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:06:37.549+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:06:37.683+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:06:37.665+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:06:37.689+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:06:37.723+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.231 seconds
[2025-07-18T21:07:08.612+0000] {processor.py:186} INFO - Started process (PID=1706) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:07:08.613+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:07:08.614+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:07:08.614+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:07:08.681+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:07:08.797+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:07:08.793+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:07:08.798+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:07:08.810+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.203 seconds
[2025-07-18T21:07:39.397+0000] {processor.py:186} INFO - Started process (PID=1729) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:07:39.398+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:07:39.399+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:07:39.399+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:07:39.452+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:07:39.571+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:07:39.565+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:07:39.572+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:07:39.589+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.198 seconds
[2025-07-18T21:08:10.198+0000] {processor.py:186} INFO - Started process (PID=1752) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:08:10.199+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:08:10.200+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:08:10.200+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:08:10.255+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:08:10.372+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:08:10.369+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:08:10.373+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:08:10.393+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.199 seconds
[2025-07-18T21:08:40.450+0000] {processor.py:186} INFO - Started process (PID=1775) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:08:40.451+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:08:40.452+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:08:40.452+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:08:40.508+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:08:40.621+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:08:40.619+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:08:40.622+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:08:40.643+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.197 seconds
[2025-07-18T21:09:11.379+0000] {processor.py:186} INFO - Started process (PID=1798) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:09:11.380+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:09:11.381+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:09:11.381+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:09:11.443+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:09:11.561+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:09:11.558+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:09:11.562+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:09:11.577+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.203 seconds
[2025-07-18T21:09:42.271+0000] {processor.py:186} INFO - Started process (PID=1813) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:09:42.272+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:09:42.273+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:09:42.272+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:09:42.356+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:09:42.484+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:09:42.474+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:09:42.486+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:09:42.500+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.234 seconds
[2025-07-18T21:10:13.470+0000] {processor.py:186} INFO - Started process (PID=1836) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:10:13.471+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:10:13.472+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:10:13.471+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:10:13.521+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:10:13.657+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:10:13.636+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:10:13.660+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:10:13.688+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.222 seconds
[2025-07-18T21:10:43.828+0000] {processor.py:186} INFO - Started process (PID=1859) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:10:43.829+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:10:43.830+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:10:43.830+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:10:43.882+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:10:44.021+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:10:43.998+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:10:44.026+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:10:44.063+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.240 seconds
[2025-07-18T21:11:14.807+0000] {processor.py:186} INFO - Started process (PID=1882) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:11:14.809+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:11:14.809+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:11:14.809+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:11:14.878+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:11:15.014+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:11:15.001+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:11:15.018+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:11:15.040+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.244 seconds
[2025-07-18T21:11:45.129+0000] {processor.py:186} INFO - Started process (PID=1905) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:11:45.130+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:11:45.131+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:11:45.130+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:11:45.184+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:11:45.311+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:11:45.300+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:11:45.315+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:11:45.331+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.206 seconds
[2025-07-18T21:12:16.389+0000] {processor.py:186} INFO - Started process (PID=1928) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:12:16.389+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:12:16.390+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:12:16.390+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:12:16.456+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:12:16.595+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:12:16.577+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:12:16.596+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:12:16.613+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.229 seconds
[2025-07-18T21:12:46.665+0000] {processor.py:186} INFO - Started process (PID=1951) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:12:46.666+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:12:46.667+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:12:46.667+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:12:46.721+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:12:46.840+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:12:46.835+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:12:46.842+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:12:46.857+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.197 seconds
[2025-07-18T21:13:17.850+0000] {processor.py:186} INFO - Started process (PID=1974) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:13:17.851+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:13:17.853+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:13:17.852+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:13:17.932+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:13:18.065+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:13:18.052+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:13:18.067+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:13:18.084+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.247 seconds
[2025-07-18T21:13:48.210+0000] {processor.py:186} INFO - Started process (PID=1997) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:13:48.211+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:13:48.212+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:13:48.212+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:13:48.260+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:13:48.390+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:13:48.376+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:13:48.393+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:13:48.420+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.214 seconds
[2025-07-18T21:14:18.783+0000] {processor.py:186} INFO - Started process (PID=2022) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:14:18.784+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:14:18.785+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:14:18.785+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:14:18.838+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:14:18.952+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:14:18.949+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:14:18.953+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:14:18.978+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.199 seconds
[2025-07-18T21:14:49.571+0000] {processor.py:186} INFO - Started process (PID=2046) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:14:49.572+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:14:49.573+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:14:49.572+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:14:49.624+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:14:49.750+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:14:49.739+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:14:49.754+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:14:49.775+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.210 seconds
[2025-07-18T21:15:20.554+0000] {processor.py:186} INFO - Started process (PID=2070) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:15:20.555+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:15:20.556+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:15:20.556+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:15:20.607+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:15:20.732+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:15:20.721+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:15:20.736+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:15:20.762+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.214 seconds
[2025-07-18T21:15:51.456+0000] {processor.py:186} INFO - Started process (PID=2104) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:15:51.457+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:15:51.458+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:15:51.458+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:15:51.506+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:15:51.633+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:15:51.620+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:15:51.635+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:15:51.652+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.201 seconds
[2025-07-18T21:16:22.265+0000] {processor.py:186} INFO - Started process (PID=2128) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:16:22.266+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:16:22.267+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:16:22.267+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:16:22.323+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:16:22.450+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:16:22.439+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:16:22.453+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:16:22.485+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.225 seconds
[2025-07-18T21:16:53.456+0000] {processor.py:186} INFO - Started process (PID=2161) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:16:53.457+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:16:53.458+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:16:53.458+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:16:53.509+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:16:53.636+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:16:53.623+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:16:53.641+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:16:53.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.208 seconds
[2025-07-18T21:17:24.415+0000] {processor.py:186} INFO - Started process (PID=2197) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:17:24.416+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:17:24.417+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:17:24.417+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:17:24.476+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:17:24.612+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:17:24.598+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:17:24.616+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:17:24.649+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.240 seconds
[2025-07-18T21:17:55.094+0000] {processor.py:186} INFO - Started process (PID=2227) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:17:55.095+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:17:55.096+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:17:55.096+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:17:55.151+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:17:55.278+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:17:55.266+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:17:55.280+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:17:55.309+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.219 seconds
[2025-07-18T21:18:25.619+0000] {processor.py:186} INFO - Started process (PID=2251) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:18:25.620+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:18:25.621+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:18:25.620+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:18:25.669+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:18:25.797+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:18:25.784+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:18:25.802+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:18:25.838+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.224 seconds
[2025-07-18T21:18:55.996+0000] {processor.py:186} INFO - Started process (PID=2275) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:18:55.997+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:18:55.998+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:18:55.998+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:18:56.047+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:18:56.182+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:18:56.162+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:18:56.186+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:18:56.205+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.213 seconds
[2025-07-18T21:19:26.426+0000] {processor.py:186} INFO - Started process (PID=2299) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:19:26.427+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:19:26.428+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:19:26.428+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:19:26.490+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:19:26.624+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:19:26.609+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:19:26.627+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:19:26.650+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.233 seconds
[2025-07-18T21:19:56.809+0000] {processor.py:186} INFO - Started process (PID=2323) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:19:56.810+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:19:56.813+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:19:56.813+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:19:56.894+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:19:57.011+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:19:57.009+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:19:57.012+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:19:57.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.227 seconds
[2025-07-18T21:20:27.107+0000] {processor.py:186} INFO - Started process (PID=2347) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:20:27.108+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:20:27.109+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:20:27.108+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:20:27.158+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:20:27.296+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:20:27.273+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:20:27.302+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:20:27.370+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.269 seconds
[2025-07-18T21:20:57.557+0000] {processor.py:186} INFO - Started process (PID=2371) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:20:57.557+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:20:57.558+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:20:57.558+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:20:57.608+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:20:57.742+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:20:57.725+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:20:57.747+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:20:57.785+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.234 seconds
[2025-07-18T21:21:27.877+0000] {processor.py:186} INFO - Started process (PID=2395) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:21:27.878+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:21:27.881+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:21:27.880+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:21:27.936+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:21:28.066+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:21:28.051+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:21:28.069+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:21:28.086+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.216 seconds
[2025-07-18T21:21:58.146+0000] {processor.py:186} INFO - Started process (PID=2419) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:21:58.147+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:21:58.148+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:21:58.148+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:21:58.197+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:21:58.338+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:21:58.329+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:21:58.341+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:21:58.370+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.229 seconds
[2025-07-18T21:22:28.546+0000] {processor.py:186} INFO - Started process (PID=2443) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:22:28.547+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:22:28.548+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:22:28.548+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:22:28.606+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:22:28.732+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:22:28.723+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:22:28.735+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:22:28.773+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.232 seconds
[2025-07-18T21:22:59.535+0000] {processor.py:186} INFO - Started process (PID=2466) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:22:59.536+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:22:59.537+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:22:59.537+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:22:59.596+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:22:59.713+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:22:59.708+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:22:59.715+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:22:59.729+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.199 seconds
[2025-07-18T21:23:30.547+0000] {processor.py:186} INFO - Started process (PID=2489) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:23:30.548+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:23:30.549+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:23:30.548+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:23:30.602+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:23:30.717+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:23:30.715+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:23:30.718+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:23:30.740+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.197 seconds
[2025-07-18T21:24:00.977+0000] {processor.py:186} INFO - Started process (PID=2512) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:24:00.978+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:24:00.979+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:24:00.979+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:24:01.038+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:24:01.154+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:24:01.151+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:24:01.155+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:24:01.168+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.195 seconds
[2025-07-18T21:24:31.791+0000] {processor.py:186} INFO - Started process (PID=2535) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:24:31.792+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:24:31.793+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:24:31.792+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:24:31.850+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:24:31.966+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:24:31.963+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:24:31.967+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:24:31.990+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.203 seconds
[2025-07-18T21:25:02.750+0000] {processor.py:186} INFO - Started process (PID=2550) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:25:02.751+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:25:02.752+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:25:02.752+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:25:02.808+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:25:02.933+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:25:02.922+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:25:02.935+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:25:02.955+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.209 seconds
[2025-07-18T21:25:33.685+0000] {processor.py:186} INFO - Started process (PID=2573) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:25:33.686+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:25:33.686+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:25:33.686+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:25:33.740+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:25:33.856+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:25:33.853+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:25:33.857+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:25:33.870+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.190 seconds
[2025-07-18T21:26:04.479+0000] {processor.py:186} INFO - Started process (PID=2596) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:26:04.480+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:26:04.481+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:26:04.481+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:26:04.528+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:26:04.658+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:26:04.644+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:26:04.661+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:26:04.683+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.210 seconds
[2025-07-18T21:26:35.062+0000] {processor.py:186} INFO - Started process (PID=2619) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:26:35.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:26:35.063+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:26:35.063+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:26:35.112+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:26:35.235+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:26:35.226+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:26:35.237+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:26:35.271+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.213 seconds
[2025-07-18T21:27:05.902+0000] {processor.py:186} INFO - Started process (PID=2642) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:27:05.903+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:27:05.904+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:27:05.903+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:27:05.963+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:27:06.087+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:27:06.077+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:27:06.090+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:27:06.109+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.212 seconds
[2025-07-18T21:27:36.996+0000] {processor.py:186} INFO - Started process (PID=2669) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:27:36.996+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:27:36.998+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:27:36.998+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:27:37.045+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:27:37.181+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:27:37.160+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:27:37.190+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:27:37.222+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.230 seconds
[2025-07-18T21:28:08.256+0000] {processor.py:186} INFO - Started process (PID=2698) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:28:08.257+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:28:08.258+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:28:08.258+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:28:08.312+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:28:08.443+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:28:08.427+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:28:08.447+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:28:08.468+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.215 seconds
[2025-07-18T21:28:38.655+0000] {processor.py:186} INFO - Started process (PID=2723) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:28:38.656+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:28:38.657+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:28:38.656+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:28:38.722+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:28:38.853+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:28:38.841+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:28:38.855+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:28:38.873+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.223 seconds
[2025-07-18T21:29:08.995+0000] {processor.py:186} INFO - Started process (PID=2746) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:29:08.995+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:29:08.996+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:29:08.996+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:29:09.045+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:29:09.179+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:29:09.160+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:29:09.182+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:29:09.199+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.208 seconds
[2025-07-18T21:29:39.749+0000] {processor.py:186} INFO - Started process (PID=2772) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:29:39.750+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:29:39.751+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:29:39.751+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:29:39.814+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:29:39.950+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:29:39.930+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:29:39.954+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:29:39.971+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.226 seconds
[2025-07-18T21:30:10.019+0000] {processor.py:186} INFO - Started process (PID=2795) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:30:10.019+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:30:10.020+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:30:10.020+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:30:10.069+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:30:10.198+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:30:10.184+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:30:10.202+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:30:10.224+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.209 seconds
[2025-07-18T21:30:41.032+0000] {processor.py:186} INFO - Started process (PID=2818) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:30:41.033+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:30:41.034+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:30:41.034+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:30:41.088+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:30:41.209+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:30:41.202+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:30:41.211+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:30:41.238+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.211 seconds
[2025-07-18T21:31:12.063+0000] {processor.py:186} INFO - Started process (PID=2841) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:31:12.064+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:31:12.065+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:31:12.064+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:31:12.116+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:31:12.229+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:31:12.227+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:31:12.230+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:31:12.241+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.183 seconds
[2025-07-18T21:31:42.398+0000] {processor.py:186} INFO - Started process (PID=2864) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:31:42.399+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:31:42.400+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:31:42.399+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:31:42.477+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:31:42.599+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:31:42.595+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:31:42.601+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:31:42.624+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.231 seconds
[2025-07-18T21:32:12.657+0000] {processor.py:186} INFO - Started process (PID=2891) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:32:12.657+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:32:12.658+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:32:12.658+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:32:12.709+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:32:12.839+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:32:12.825+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:32:12.842+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:32:12.867+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.214 seconds
[2025-07-18T21:32:42.897+0000] {processor.py:186} INFO - Started process (PID=2915) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:32:42.898+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:32:42.899+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:32:42.899+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:32:42.949+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:32:43.079+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:32:43.063+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:32:43.087+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:32:43.126+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.232 seconds
[2025-07-18T21:33:13.419+0000] {processor.py:186} INFO - Started process (PID=2939) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:33:13.420+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:33:13.421+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:33:13.420+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:33:13.494+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:33:13.617+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:33:13.613+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:33:13.618+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:33:13.631+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.216 seconds
[2025-07-18T21:33:43.820+0000] {processor.py:186} INFO - Started process (PID=2963) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:33:43.821+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:33:43.822+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:33:43.822+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:33:43.879+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:33:43.996+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:33:43.993+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:33:43.997+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:33:44.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.193 seconds
[2025-07-18T21:34:14.095+0000] {processor.py:186} INFO - Started process (PID=2987) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:34:14.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:34:14.098+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:34:14.098+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:34:14.147+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:34:14.264+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:34:14.259+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:34:14.266+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:34:14.295+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.204 seconds
[2025-07-18T21:34:44.644+0000] {processor.py:186} INFO - Started process (PID=3011) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:34:44.644+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:34:44.645+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:34:44.645+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:34:44.700+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:34:44.830+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:34:44.816+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:34:44.834+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:34:44.867+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.227 seconds
[2025-07-18T21:35:15.203+0000] {processor.py:186} INFO - Started process (PID=3035) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:35:15.204+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:35:15.206+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:35:15.205+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:35:15.304+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:35:15.436+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:35:15.433+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:35:15.437+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:35:15.459+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.261 seconds
[2025-07-18T21:35:45.896+0000] {processor.py:186} INFO - Started process (PID=3059) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:35:45.896+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:35:45.897+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:35:45.897+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:35:45.973+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:35:46.103+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:35:46.088+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:35:46.106+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:35:46.149+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.257 seconds
[2025-07-18T21:36:16.263+0000] {processor.py:186} INFO - Started process (PID=3083) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:36:16.265+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:36:16.266+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:36:16.266+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:36:16.346+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:36:16.499+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:36:16.490+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:36:16.500+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:36:16.529+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.271 seconds
[2025-07-18T21:36:46.738+0000] {processor.py:186} INFO - Started process (PID=3107) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:36:46.739+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:36:46.740+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:36:46.739+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:36:46.791+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:36:46.912+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:36:46.904+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:36:46.913+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:36:46.925+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.191 seconds
[2025-07-18T21:37:17.138+0000] {processor.py:186} INFO - Started process (PID=3131) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:37:17.139+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:37:17.144+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:37:17.144+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:37:17.204+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:37:17.320+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:37:17.318+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:37:17.321+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:37:17.333+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.200 seconds
[2025-07-18T21:37:47.388+0000] {processor.py:186} INFO - Started process (PID=3155) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:37:47.391+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:37:47.394+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:37:47.393+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:37:47.444+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:37:47.575+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:37:47.558+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:37:47.578+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:37:47.592+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.208 seconds
[2025-07-18T21:38:17.758+0000] {processor.py:186} INFO - Started process (PID=3179) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:38:17.764+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:38:17.765+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:38:17.765+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:38:17.818+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:38:17.947+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:38:17.933+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:38:17.951+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:38:17.978+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.224 seconds
[2025-07-18T21:38:48.120+0000] {processor.py:186} INFO - Started process (PID=3203) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:38:48.121+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:38:48.122+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:38:48.122+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:38:48.174+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:38:48.288+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:38:48.286+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:38:48.289+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:38:48.302+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.186 seconds
[2025-07-18T21:39:18.597+0000] {processor.py:186} INFO - Started process (PID=3219) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:39:18.598+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:39:18.599+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:39:18.599+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:39:18.647+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:39:18.781+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:39:18.763+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:39:18.785+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:39:18.823+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.230 seconds
[2025-07-18T21:39:48.919+0000] {processor.py:186} INFO - Started process (PID=3243) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:39:48.920+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:39:48.921+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:39:48.921+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:39:48.993+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:39:49.108+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:39:49.106+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:39:49.109+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:39:49.122+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.207 seconds
[2025-07-18T21:40:20.134+0000] {processor.py:186} INFO - Started process (PID=3267) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:40:20.135+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:40:20.136+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:40:20.136+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:40:20.198+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:40:20.327+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:40:20.319+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:40:20.331+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:40:20.361+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.232 seconds
[2025-07-18T21:40:50.463+0000] {processor.py:186} INFO - Started process (PID=3291) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:40:50.464+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:40:50.465+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:40:50.465+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:40:50.524+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:40:50.638+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:40:50.636+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:40:50.639+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:40:50.651+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.192 seconds
[2025-07-18T21:41:20.940+0000] {processor.py:186} INFO - Started process (PID=3315) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:41:20.942+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:41:20.944+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:41:20.944+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:41:21.031+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:41:21.169+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:41:21.147+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:41:21.171+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:41:21.187+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.254 seconds
[2025-07-18T21:41:51.267+0000] {processor.py:186} INFO - Started process (PID=3339) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:41:51.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:41:51.269+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:41:51.269+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:41:51.326+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:41:51.456+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:41:51.441+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:41:51.460+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:41:51.483+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.220 seconds
[2025-07-18T21:42:21.573+0000] {processor.py:186} INFO - Started process (PID=3363) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:42:21.574+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:42:21.575+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:42:21.575+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:42:21.634+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:42:21.751+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:42:21.749+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:42:21.753+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:42:21.766+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.198 seconds
[2025-07-18T21:42:52.756+0000] {processor.py:186} INFO - Started process (PID=3387) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:42:52.757+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:42:52.758+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:42:52.758+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:42:52.814+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:42:52.948+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:42:52.930+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:42:52.951+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:42:52.980+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.229 seconds
[2025-07-18T21:43:24.014+0000] {processor.py:186} INFO - Started process (PID=3411) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:43:24.015+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:43:24.015+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:43:24.015+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:43:24.069+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:43:24.198+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:43:24.184+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:43:24.200+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:43:24.221+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.211 seconds
[2025-07-18T21:43:55.159+0000] {processor.py:186} INFO - Started process (PID=3435) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:43:55.160+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:43:55.161+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:43:55.161+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:43:55.213+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:43:55.348+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:43:55.329+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:43:55.353+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:43:55.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.228 seconds
[2025-07-18T21:44:26.415+0000] {processor.py:186} INFO - Started process (PID=3459) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:44:26.416+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:44:26.417+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:44:26.416+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:44:26.467+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:44:26.595+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:44:26.581+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:44:26.598+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:44:26.629+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.218 seconds
[2025-07-18T21:44:56.722+0000] {processor.py:186} INFO - Started process (PID=3483) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:44:56.723+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:44:56.724+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:44:56.724+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:44:56.792+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:44:56.913+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:44:56.908+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:44:56.914+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:44:56.930+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.213 seconds
[2025-07-18T21:45:27.736+0000] {processor.py:186} INFO - Started process (PID=3507) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:45:27.737+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:45:27.738+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:45:27.738+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:45:27.809+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:45:27.925+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:45:27.923+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:45:27.926+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:45:27.949+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.218 seconds
[2025-07-18T21:45:58.866+0000] {processor.py:186} INFO - Started process (PID=3531) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:45:58.867+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:45:58.867+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:45:58.867+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:45:58.916+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:45:59.034+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:45:59.029+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:45:59.036+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:45:59.057+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.195 seconds
[2025-07-18T21:46:29.901+0000] {processor.py:186} INFO - Started process (PID=3555) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:46:29.902+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:46:29.903+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:46:29.903+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:46:29.956+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:46:30.081+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:46:30.070+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:46:30.085+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:46:30.111+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.214 seconds
[2025-07-18T21:47:01.109+0000] {processor.py:186} INFO - Started process (PID=3579) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:47:01.110+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:47:01.111+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:47:01.111+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:47:01.166+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:47:01.298+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:47:01.284+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:47:01.301+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:47:01.326+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.221 seconds
[2025-07-18T21:47:31.476+0000] {processor.py:186} INFO - Started process (PID=3603) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:47:31.477+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:47:31.478+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:47:31.478+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:47:31.537+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:47:31.667+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:47:31.653+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:47:31.671+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:47:31.706+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.234 seconds
[2025-07-18T21:48:01.780+0000] {processor.py:186} INFO - Started process (PID=3627) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:48:01.781+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:48:01.782+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:48:01.782+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:48:01.837+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:48:01.961+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:48:01.951+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:48:01.963+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:48:01.980+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.204 seconds
[2025-07-18T21:48:32.091+0000] {processor.py:186} INFO - Started process (PID=3651) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:48:32.092+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:48:32.093+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:48:32.093+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:48:32.146+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:48:32.269+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:48:32.260+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:48:32.272+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:48:32.301+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.214 seconds
[2025-07-18T21:49:02.549+0000] {processor.py:186} INFO - Started process (PID=3675) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:49:02.550+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:49:02.551+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:49:02.550+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:49:02.600+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:49:02.743+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:49:02.715+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:49:02.754+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:49:02.781+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.235 seconds
[2025-07-18T21:49:33.215+0000] {processor.py:186} INFO - Started process (PID=3699) to work on /opt/airflow/dags/dags.py
[2025-07-18T21:49:33.216+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T21:49:33.217+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:49:33.217+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T21:49:33.303+0000] {logging_mixin.py:190} INFO - PySpark is available
[2025-07-18T21:49:33.426+0000] {logging_mixin.py:190} INFO - [2025-07-18T21:49:33.421+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 6, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 27, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-18T21:49:33.428+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-18T21:49:33.446+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.236 seconds
[2025-07-18T22:00:54.172+0000] {processor.py:186} INFO - Started process (PID=56) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:00:54.173+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:00:54.175+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:00:54.175+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:00:54.187+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:00:54.193+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:00:54.263+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:00:54.263+0000] {override.py:1900} INFO - Created Permission View: can edit on DAG:etl_pipeline
[2025-07-18T22:00:54.269+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:00:54.269+0000] {override.py:1900} INFO - Created Permission View: can read on DAG:etl_pipeline
[2025-07-18T22:00:54.273+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:00:54.273+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG:etl_pipeline
[2025-07-18T22:00:54.277+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:00:54.276+0000] {override.py:1900} INFO - Created Permission View: can read on DAG Run:etl_pipeline
[2025-07-18T22:00:54.280+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:00:54.280+0000] {override.py:1900} INFO - Created Permission View: menu access on DAG Run:etl_pipeline
[2025-07-18T22:00:54.283+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:00:54.283+0000] {override.py:1900} INFO - Created Permission View: can create on DAG Run:etl_pipeline
[2025-07-18T22:00:54.287+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:00:54.286+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG Run:etl_pipeline
[2025-07-18T22:00:54.287+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:00:54.287+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:00:54.297+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:00:54.296+0000] {dag.py:3262} INFO - Creating ORM DAG for etl_pipeline
[2025-07-18T22:00:54.304+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:00:54.304+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:00:54.315+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.148 seconds
[2025-07-18T22:01:25.171+0000] {processor.py:186} INFO - Started process (PID=72) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:01:25.172+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:01:25.174+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:01:25.173+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:01:25.187+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:01:25.193+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:01:25.209+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:01:25.209+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:01:25.225+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:01:25.225+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:01:25.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.069 seconds
[2025-07-18T22:01:56.160+0000] {processor.py:186} INFO - Started process (PID=88) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:01:56.160+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:01:56.162+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:01:56.162+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:01:56.170+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:01:56.176+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:01:56.194+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:01:56.194+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:01:56.210+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:01:56.210+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:01:56.221+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.066 seconds
[2025-07-18T22:02:26.930+0000] {processor.py:186} INFO - Started process (PID=320) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:02:26.931+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:02:26.932+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:02:26.932+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:02:26.941+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:02:26.946+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:02:26.963+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:02:26.963+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:02:26.977+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:02:26.977+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:02:26.989+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.063 seconds
[2025-07-18T22:02:57.861+0000] {processor.py:186} INFO - Started process (PID=336) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:02:57.862+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:02:57.863+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:02:57.863+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:02:57.877+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:02:57.884+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:02:57.903+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:02:57.903+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:02:57.921+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:02:57.920+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:02:57.932+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.078 seconds
[2025-07-18T22:03:28.096+0000] {processor.py:186} INFO - Started process (PID=354) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:03:28.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:03:28.098+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:03:28.098+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:03:28.108+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:03:28.114+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:03:28.132+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:03:28.132+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:03:28.147+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:03:28.146+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:03:28.159+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.067 seconds
[2025-07-18T22:03:58.798+0000] {processor.py:186} INFO - Started process (PID=478) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:03:58.799+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:03:58.801+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:03:58.800+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:03:58.809+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:03:58.815+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:03:58.832+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:03:58.831+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:03:58.847+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:03:58.847+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:03:58.859+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.065 seconds
[2025-07-18T22:04:29.584+0000] {processor.py:186} INFO - Started process (PID=494) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:04:29.586+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:04:29.588+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:04:29.588+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:04:29.630+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:04:29.641+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:04:29.665+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:04:29.664+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:04:29.681+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:04:29.680+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:04:29.692+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.112 seconds
[2025-07-18T22:05:00.505+0000] {processor.py:186} INFO - Started process (PID=510) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:05:00.505+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:05:00.507+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:05:00.507+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:05:00.516+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:05:00.521+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:05:00.537+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:05:00.537+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:05:00.551+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:05:00.551+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:05:00.561+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.060 seconds
[2025-07-18T22:05:31.637+0000] {processor.py:186} INFO - Started process (PID=526) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:05:31.638+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:05:31.639+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:05:31.639+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:05:31.648+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:05:31.653+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:05:31.669+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:05:31.669+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:05:31.684+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:05:31.684+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:05:31.695+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.062 seconds
[2025-07-18T22:06:01.913+0000] {processor.py:186} INFO - Started process (PID=542) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:06:01.913+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:06:01.915+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:06:01.915+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:06:01.923+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:06:01.929+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:06:01.944+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:06:01.944+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:06:01.958+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:06:01.958+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:06:01.971+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.062 seconds
[2025-07-18T22:06:32.170+0000] {processor.py:186} INFO - Started process (PID=558) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:06:32.172+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:06:32.174+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:06:32.174+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:06:32.218+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:06:32.225+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:06:32.243+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:06:32.243+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:06:32.262+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:06:32.262+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:06:32.275+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.110 seconds
[2025-07-18T22:07:02.453+0000] {processor.py:186} INFO - Started process (PID=574) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:07:02.453+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:07:02.455+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:07:02.455+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:07:02.464+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:07:02.470+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:07:02.485+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:07:02.485+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:07:02.500+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:07:02.499+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:07:02.510+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.061 seconds
[2025-07-18T22:07:32.578+0000] {processor.py:186} INFO - Started process (PID=590) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:07:32.579+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:07:32.581+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:07:32.580+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:07:32.589+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:07:32.595+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:07:32.611+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:07:32.611+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:07:32.625+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:07:32.625+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:07:32.636+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.063 seconds
[2025-07-18T22:08:02.688+0000] {processor.py:186} INFO - Started process (PID=606) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:08:02.689+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:08:02.690+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:08:02.690+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:08:02.702+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:08:02.709+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:08:02.726+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:08:02.726+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:08:02.741+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:08:02.740+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:08:02.753+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.069 seconds
[2025-07-18T22:08:33.152+0000] {processor.py:186} INFO - Started process (PID=622) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:08:33.153+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:08:33.155+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:08:33.155+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:08:33.172+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:08:33.179+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:08:33.194+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:08:33.194+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:08:33.209+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:08:33.209+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:08:33.220+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.072 seconds
[2025-07-18T22:09:04.200+0000] {processor.py:186} INFO - Started process (PID=638) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:09:04.200+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:09:04.202+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:09:04.201+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:09:04.213+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:09:04.218+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:09:04.235+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:09:04.235+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:09:04.252+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:09:04.252+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:09:04.264+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.068 seconds
[2025-07-18T22:09:34.333+0000] {processor.py:186} INFO - Started process (PID=652) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:09:34.333+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:09:34.335+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:09:34.335+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:09:34.343+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:09:34.349+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:09:34.365+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:09:34.365+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:09:34.380+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:09:34.380+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:09:34.390+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.061 seconds
[2025-07-18T22:10:05.356+0000] {processor.py:186} INFO - Started process (PID=670) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:10:05.357+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:10:05.359+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:10:05.359+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:10:05.367+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:10:05.374+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:10:05.392+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:10:05.392+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:10:05.408+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:10:05.408+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:10:05.420+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.068 seconds
[2025-07-18T22:10:36.306+0000] {processor.py:186} INFO - Started process (PID=686) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:10:36.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:10:36.309+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:10:36.309+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:10:36.320+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:10:36.326+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:10:36.343+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:10:36.343+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:10:36.361+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:10:36.361+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:10:36.374+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.072 seconds
[2025-07-18T22:11:07.464+0000] {processor.py:186} INFO - Started process (PID=702) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:11:07.465+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:11:07.467+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:11:07.466+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:11:07.476+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:11:07.482+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:11:07.499+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:11:07.499+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:11:07.514+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:11:07.514+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:11:07.525+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.065 seconds
[2025-07-18T22:11:38.323+0000] {processor.py:186} INFO - Started process (PID=718) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:11:38.324+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:11:38.326+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:11:38.326+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:11:38.334+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:11:38.340+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:11:38.357+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:11:38.357+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:11:38.374+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:11:38.373+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:11:38.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.066 seconds
[2025-07-18T22:12:09.348+0000] {processor.py:186} INFO - Started process (PID=734) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:12:09.349+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:12:09.351+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:12:09.350+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:12:09.359+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:12:09.366+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:12:09.385+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:12:09.385+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:12:09.403+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:12:09.403+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:12:09.415+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.071 seconds
[2025-07-18T22:12:40.399+0000] {processor.py:186} INFO - Started process (PID=750) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:12:40.400+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:12:40.402+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:12:40.401+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:12:40.410+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:12:40.416+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:12:40.434+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:12:40.433+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:12:40.450+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:12:40.450+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:12:40.463+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.067 seconds
[2025-07-18T22:13:11.314+0000] {processor.py:186} INFO - Started process (PID=766) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:13:11.314+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:13:11.316+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:13:11.316+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:13:11.325+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:13:11.331+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:13:11.348+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:13:11.348+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:13:11.364+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:13:11.364+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:13:11.377+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.067 seconds
[2025-07-18T22:13:42.328+0000] {processor.py:186} INFO - Started process (PID=782) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:13:42.329+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:13:42.331+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:13:42.331+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:13:42.342+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:13:42.348+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:13:42.364+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:13:42.364+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:13:42.381+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:13:42.381+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:13:42.394+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.070 seconds
[2025-07-18T22:14:13.347+0000] {processor.py:186} INFO - Started process (PID=798) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:14:13.348+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:14:13.349+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:14:13.349+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:14:13.359+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:14:13.367+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:14:13.391+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:14:13.391+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:14:13.407+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:14:13.407+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:14:13.418+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.076 seconds
[2025-07-18T22:14:43.462+0000] {processor.py:186} INFO - Started process (PID=812) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:14:43.463+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:14:43.465+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:14:43.464+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:14:43.476+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:14:43.482+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:14:43.499+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:14:43.499+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:14:43.514+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:14:43.514+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:14:43.526+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.068 seconds
[2025-07-18T22:15:13.678+0000] {processor.py:186} INFO - Started process (PID=828) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:15:13.679+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:15:13.680+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:15:13.680+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:15:13.693+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:15:13.700+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:15:13.717+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:15:13.717+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:15:13.733+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:15:13.733+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:15:13.747+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.073 seconds
[2025-07-18T22:15:43.922+0000] {processor.py:186} INFO - Started process (PID=836) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:15:43.923+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:15:43.924+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:15:43.924+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:15:43.935+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:15:43.941+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:15:43.957+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:15:43.957+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:15:43.972+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:15:43.971+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:15:43.983+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.066 seconds
[2025-07-18T22:16:14.165+0000] {processor.py:186} INFO - Started process (PID=852) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:16:14.166+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:16:14.168+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:16:14.167+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:16:14.183+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:16:14.190+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:16:14.206+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:16:14.206+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:16:14.221+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:16:14.220+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:16:14.232+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.071 seconds
[2025-07-18T22:16:44.432+0000] {processor.py:186} INFO - Started process (PID=868) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:16:44.432+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:16:44.434+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:16:44.434+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:16:44.443+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:16:44.449+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:16:44.469+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:16:44.469+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:16:44.491+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:16:44.491+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:16:44.508+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.080 seconds
[2025-07-18T22:17:14.621+0000] {processor.py:186} INFO - Started process (PID=884) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:17:14.622+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:17:14.624+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:17:14.623+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:17:14.639+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:17:14.646+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:17:14.664+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:17:14.664+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:17:14.681+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:17:14.681+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:17:14.696+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.079 seconds
[2025-07-18T22:17:44.792+0000] {processor.py:186} INFO - Started process (PID=900) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:17:44.792+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:17:44.794+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:17:44.794+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:17:44.805+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:17:44.810+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:17:44.827+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:17:44.827+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:17:44.842+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:17:44.841+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:17:44.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.066 seconds
[2025-07-18T22:18:15.618+0000] {processor.py:186} INFO - Started process (PID=916) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:18:15.619+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:18:15.626+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:18:15.625+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:18:15.645+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:18:15.652+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:18:15.674+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:18:15.674+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:18:15.690+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:18:15.690+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:18:15.703+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.091 seconds
[2025-07-18T22:18:45.824+0000] {processor.py:186} INFO - Started process (PID=932) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:18:45.824+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:18:45.826+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:18:45.826+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:18:45.835+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:18:45.841+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:18:45.857+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:18:45.857+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:18:45.873+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:18:45.873+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:18:45.885+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.065 seconds
[2025-07-18T22:19:15.998+0000] {processor.py:186} INFO - Started process (PID=948) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:19:15.999+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:19:16.000+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:19:16.000+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:19:16.009+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:19:16.016+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:19:16.034+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:19:16.033+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:19:16.050+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:19:16.050+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:19:16.061+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.067 seconds
[2025-07-18T22:19:46.780+0000] {processor.py:186} INFO - Started process (PID=964) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:19:46.781+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:19:46.783+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:19:46.782+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:19:46.795+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:19:46.801+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:19:46.818+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:19:46.817+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:19:46.833+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:19:46.833+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:19:46.844+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.069 seconds
[2025-07-18T22:20:17.485+0000] {processor.py:186} INFO - Started process (PID=980) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:20:17.486+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:20:17.488+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:20:17.487+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:20:17.502+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:20:17.508+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:20:17.525+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:20:17.525+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:20:17.540+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:20:17.540+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:20:17.551+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.070 seconds
[2025-07-18T22:20:48.429+0000] {processor.py:186} INFO - Started process (PID=996) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:20:48.430+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:20:48.431+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:20:48.431+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:20:48.442+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:20:48.448+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:20:48.466+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:20:48.466+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:20:48.481+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:20:48.481+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:20:48.491+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.066 seconds
[2025-07-18T22:21:18.834+0000] {processor.py:186} INFO - Started process (PID=1012) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:21:18.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:21:18.837+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:21:18.836+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:21:18.844+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:21:18.850+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:21:18.865+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:21:18.865+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:21:18.879+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:21:18.879+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:21:18.890+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.060 seconds
[2025-07-18T22:21:49.030+0000] {processor.py:186} INFO - Started process (PID=1028) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:21:49.031+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:21:49.033+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:21:49.033+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:21:49.040+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:21:49.046+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:21:49.064+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:21:49.064+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:21:49.080+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:21:49.079+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:21:49.090+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.064 seconds
[2025-07-18T22:22:19.394+0000] {processor.py:186} INFO - Started process (PID=1044) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:22:19.395+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:22:19.396+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:22:19.396+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:22:19.408+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:22:19.414+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:22:19.430+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:22:19.430+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:22:19.445+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:22:19.444+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:22:19.456+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.066 seconds
[2025-07-18T22:22:49.613+0000] {processor.py:186} INFO - Started process (PID=1060) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:22:49.614+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:22:49.616+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:22:49.615+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:22:49.625+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:22:49.631+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:22:49.647+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:22:49.647+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:22:49.665+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:22:49.664+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:22:49.676+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.067 seconds
[2025-07-18T22:23:19.839+0000] {processor.py:186} INFO - Started process (PID=1076) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:23:19.839+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:23:19.841+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:23:19.841+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:23:19.849+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:23:19.855+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:23:19.871+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:23:19.871+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:23:19.886+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:23:19.886+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:23:19.898+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.064 seconds
[2025-07-18T22:23:50.580+0000] {processor.py:186} INFO - Started process (PID=1092) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:23:50.581+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:23:50.583+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:23:50.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:23:50.595+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:23:50.601+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:23:50.618+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:23:50.617+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:23:50.633+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:23:50.633+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:23:50.645+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.069 seconds
[2025-07-18T22:24:20.830+0000] {processor.py:186} INFO - Started process (PID=1108) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:24:20.831+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:24:20.833+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:24:20.833+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:24:20.845+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:24:20.851+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:24:20.868+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:24:20.868+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:24:20.884+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:24:20.884+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:24:20.899+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.073 seconds
[2025-07-18T22:24:51.050+0000] {processor.py:186} INFO - Started process (PID=1124) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:24:51.050+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:24:51.052+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:24:51.052+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:24:51.061+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:24:51.067+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:24:51.083+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:24:51.083+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:24:51.098+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:24:51.098+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:24:51.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.064 seconds
[2025-07-18T22:25:21.295+0000] {processor.py:186} INFO - Started process (PID=1140) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:25:21.296+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:25:21.297+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:25:21.297+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:25:21.307+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:25:21.312+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:25:21.328+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:25:21.328+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:25:21.343+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:25:21.343+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:25:21.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.064 seconds
[2025-07-18T22:25:51.963+0000] {processor.py:186} INFO - Started process (PID=1156) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:25:51.964+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:25:51.965+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:25:51.965+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:25:51.975+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:25:51.981+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:25:51.997+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:25:51.996+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:25:52.011+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:25:52.011+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:25:52.021+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.062 seconds
[2025-07-18T22:26:22.243+0000] {processor.py:186} INFO - Started process (PID=1172) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:26:22.245+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:26:22.247+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:26:22.247+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:26:22.266+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:26:22.275+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:26:22.295+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:26:22.295+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:26:22.322+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:26:22.322+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:26:22.341+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.103 seconds
[2025-07-18T22:26:52.415+0000] {processor.py:186} INFO - Started process (PID=1180) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:26:52.416+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:26:52.417+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:26:52.417+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:26:52.425+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:26:52.430+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:26:52.446+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:26:52.445+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:26:52.460+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:26:52.460+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:26:52.470+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.059 seconds
[2025-07-18T22:27:22.724+0000] {processor.py:186} INFO - Started process (PID=1196) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:27:22.725+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:27:22.727+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:27:22.726+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:27:22.737+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:27:22.742+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:27:22.758+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:27:22.758+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:27:22.773+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:27:22.773+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:27:22.783+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.063 seconds
[2025-07-18T22:27:53.113+0000] {processor.py:186} INFO - Started process (PID=1212) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:27:53.114+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:27:53.115+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:27:53.115+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:27:53.124+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:27:53.129+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:27:53.145+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:27:53.144+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:27:53.159+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:27:53.159+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:27:53.170+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.061 seconds
[2025-07-18T22:28:23.343+0000] {processor.py:186} INFO - Started process (PID=1228) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:28:23.343+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:28:23.345+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:28:23.345+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:28:23.354+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:28:23.359+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:28:23.374+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:28:23.374+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:28:23.388+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:28:23.388+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:28:23.398+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.059 seconds
[2025-07-18T22:28:53.583+0000] {processor.py:186} INFO - Started process (PID=1244) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:28:53.583+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:28:53.585+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:28:53.585+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:28:53.593+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:28:53.599+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:28:53.616+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:28:53.616+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:28:53.630+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:28:53.630+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:28:53.641+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.062 seconds
[2025-07-18T22:29:23.799+0000] {processor.py:186} INFO - Started process (PID=1260) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:29:23.800+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:29:23.802+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:29:23.802+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:29:23.810+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:29:23.815+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:29:23.831+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:29:23.831+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:29:23.846+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:29:23.846+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:29:23.858+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.063 seconds
[2025-07-18T22:29:53.933+0000] {processor.py:186} INFO - Started process (PID=1276) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:29:53.934+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:29:53.936+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:29:53.935+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:29:53.944+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:29:53.950+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:29:53.967+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:29:53.967+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:29:53.981+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:29:53.981+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:29:53.992+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.064 seconds
[2025-07-18T22:30:24.196+0000] {processor.py:186} INFO - Started process (PID=1292) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:30:24.197+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:30:24.199+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:30:24.198+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:30:24.209+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:30:24.215+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:30:24.230+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:30:24.230+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:30:24.244+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:30:24.244+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:30:24.255+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.063 seconds
[2025-07-18T22:30:54.532+0000] {processor.py:186} INFO - Started process (PID=1308) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:30:54.533+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:30:54.535+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:30:54.535+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:30:54.550+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:30:54.556+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:30:54.573+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:30:54.572+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:30:54.587+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:30:54.587+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:30:54.598+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.070 seconds
[2025-07-18T22:31:24.840+0000] {processor.py:186} INFO - Started process (PID=1324) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:31:24.840+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:31:24.842+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:31:24.842+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:31:24.854+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:31:24.861+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:31:24.879+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:31:24.879+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:31:24.895+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:31:24.895+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:31:24.907+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.072 seconds
[2025-07-18T22:31:54.994+0000] {processor.py:186} INFO - Started process (PID=1340) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:31:54.994+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:31:54.996+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:31:54.996+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:31:55.006+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:31:55.012+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:31:55.027+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:31:55.027+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:31:55.043+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:31:55.042+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:31:55.053+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.064 seconds
[2025-07-18T22:32:25.171+0000] {processor.py:186} INFO - Started process (PID=1356) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:32:25.172+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:32:25.174+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:32:25.174+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:32:25.186+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:32:25.191+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:32:25.208+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:32:25.208+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:32:25.222+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:32:25.222+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:32:25.234+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.067 seconds
[2025-07-18T22:32:55.844+0000] {processor.py:186} INFO - Started process (PID=1372) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:32:55.844+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:32:55.849+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:32:55.847+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:32:55.858+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:32:55.864+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:32:55.879+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:32:55.879+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:32:55.897+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:32:55.897+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:32:55.908+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.068 seconds
[2025-07-18T22:33:26.117+0000] {processor.py:186} INFO - Started process (PID=1388) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:33:26.118+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:33:26.119+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:33:26.119+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:33:26.128+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:33:26.134+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:33:26.149+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:33:26.149+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:33:26.163+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:33:26.163+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:33:26.173+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.060 seconds
[2025-07-18T22:33:56.429+0000] {processor.py:186} INFO - Started process (PID=1404) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:33:56.430+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:33:56.432+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:33:56.432+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:33:56.442+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:33:56.447+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:33:56.463+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:33:56.463+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:33:56.477+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:33:56.477+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:33:56.488+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.063 seconds
[2025-07-18T22:34:26.580+0000] {processor.py:186} INFO - Started process (PID=1420) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:34:26.581+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:34:26.582+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:34:26.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:34:26.590+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:34:26.596+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:34:26.613+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:34:26.613+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:34:26.628+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:34:26.628+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:34:26.639+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.063 seconds
[2025-07-18T22:34:57.662+0000] {processor.py:186} INFO - Started process (PID=1436) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:34:57.662+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:34:57.664+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:34:57.664+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:34:57.672+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:34:57.677+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:34:57.694+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:34:57.694+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:34:57.710+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:34:57.709+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:34:57.721+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.063 seconds
[2025-07-18T22:35:28.108+0000] {processor.py:186} INFO - Started process (PID=1452) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:35:28.109+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:35:28.111+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:35:28.111+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:35:28.123+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:35:28.129+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:35:28.147+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:35:28.147+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:35:28.164+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:35:28.163+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:35:28.177+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.072 seconds
[2025-07-18T22:35:58.559+0000] {processor.py:186} INFO - Started process (PID=1468) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:35:58.560+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:35:58.561+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:35:58.561+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:35:58.570+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:35:58.576+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:35:58.592+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:35:58.592+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:35:58.607+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:35:58.607+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:35:58.618+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.063 seconds
[2025-07-18T22:36:28.768+0000] {processor.py:186} INFO - Started process (PID=1483) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:36:28.768+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:36:28.770+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:36:28.770+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:36:28.779+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:36:28.784+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:36:28.801+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:36:28.801+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:36:28.816+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:36:28.816+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:36:28.942+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.178 seconds
[2025-07-18T22:36:59.046+0000] {processor.py:186} INFO - Started process (PID=1498) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:36:59.047+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:36:59.048+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:36:59.048+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:36:59.057+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:36:59.063+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:36:59.078+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:36:59.078+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:36:59.093+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:36:59.093+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:36:59.103+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.061 seconds
[2025-07-18T22:37:29.226+0000] {processor.py:186} INFO - Started process (PID=1514) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:37:29.229+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:37:29.231+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:37:29.231+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:37:29.245+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:37:29.255+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:37:29.271+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:37:29.271+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:37:29.286+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:37:29.286+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:37:29.300+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.078 seconds
[2025-07-18T22:37:59.952+0000] {processor.py:186} INFO - Started process (PID=1530) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:37:59.953+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:37:59.956+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:37:59.955+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:37:59.969+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:37:59.975+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:37:59.992+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:37:59.992+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:38:00.008+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:38:00.008+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:38:00.024+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.076 seconds
[2025-07-18T22:38:30.821+0000] {processor.py:186} INFO - Started process (PID=1538) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:38:30.822+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:38:30.825+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:38:30.824+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:38:30.839+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:38:30.846+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:38:30.862+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:38:30.862+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:38:30.876+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:38:30.876+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:38:30.887+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.072 seconds
[2025-07-18T22:39:00.934+0000] {processor.py:186} INFO - Started process (PID=1554) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:39:00.935+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:39:00.939+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:39:00.936+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:39:00.950+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:39:00.958+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:39:00.977+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:39:00.977+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:39:00.998+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:39:00.997+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:39:01.012+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.082 seconds
[2025-07-18T22:39:31.635+0000] {processor.py:186} INFO - Started process (PID=1570) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:39:31.642+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:39:31.644+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:39:31.644+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:39:31.653+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:39:31.658+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:39:31.675+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:39:31.675+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:39:31.690+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:39:31.690+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:39:31.701+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.069 seconds
[2025-07-18T22:40:02.506+0000] {processor.py:186} INFO - Started process (PID=1586) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:40:02.509+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:40:02.512+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:40:02.512+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:40:02.522+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:40:02.528+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:40:02.543+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:40:02.543+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:40:02.558+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:40:02.558+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:40:02.568+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.066 seconds
[2025-07-18T22:40:33.330+0000] {processor.py:186} INFO - Started process (PID=1602) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:40:33.331+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:40:33.335+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:40:33.335+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:40:33.343+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:40:33.349+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:40:33.364+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:40:33.364+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:40:33.378+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:40:33.378+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:40:33.388+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.063 seconds
[2025-07-18T22:41:04.152+0000] {processor.py:186} INFO - Started process (PID=1618) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:41:04.153+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:41:04.156+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:41:04.155+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:41:04.169+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:41:04.176+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:41:04.192+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:41:04.192+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:41:04.207+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:41:04.207+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:41:04.218+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.071 seconds
[2025-07-18T22:41:34.579+0000] {processor.py:186} INFO - Started process (PID=1634) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:41:34.581+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:41:34.584+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:41:34.583+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:41:34.597+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:41:34.603+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:41:34.620+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:41:34.620+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:41:34.637+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:41:34.637+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:41:34.749+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.174 seconds
[2025-07-18T22:42:04.866+0000] {processor.py:186} INFO - Started process (PID=1650) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:42:04.867+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:42:04.869+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:42:04.869+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:42:04.883+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:42:04.890+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:42:04.911+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:42:04.910+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:42:04.929+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:42:04.929+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:42:04.944+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.082 seconds
[2025-07-18T22:42:35.260+0000] {processor.py:186} INFO - Started process (PID=1666) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:42:35.261+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:42:35.263+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:42:35.263+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:42:35.283+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:42:35.289+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:42:35.305+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:42:35.305+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:42:35.319+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:42:35.319+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:42:35.333+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.077 seconds
[2025-07-18T22:43:05.678+0000] {processor.py:186} INFO - Started process (PID=1682) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:43:05.679+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:43:05.681+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:43:05.680+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:43:05.698+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:43:05.705+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:43:05.724+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:43:05.724+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:43:05.742+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:43:05.741+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:43:05.756+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.083 seconds
[2025-07-18T22:43:35.908+0000] {processor.py:186} INFO - Started process (PID=1698) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:43:35.908+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:43:35.910+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:43:35.910+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:43:35.918+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:43:35.923+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:43:35.939+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:43:35.939+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:43:35.953+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:43:35.953+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:43:35.963+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.059 seconds
[2025-07-18T22:44:06.068+0000] {processor.py:186} INFO - Started process (PID=1714) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:44:06.069+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:44:06.070+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:44:06.070+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:44:06.078+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:44:06.085+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:44:06.104+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:44:06.104+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:44:06.121+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:44:06.121+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:44:06.134+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.071 seconds
[2025-07-18T22:44:36.337+0000] {processor.py:186} INFO - Started process (PID=1730) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:44:36.337+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:44:36.339+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:44:36.339+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:44:36.347+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:44:36.353+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:44:36.368+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:44:36.368+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:44:36.382+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:44:36.382+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:44:36.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.060 seconds
[2025-07-18T22:45:06.598+0000] {processor.py:186} INFO - Started process (PID=1746) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:45:06.598+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:45:06.600+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:45:06.600+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:45:06.608+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:45:06.614+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:45:06.630+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:45:06.630+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:45:06.644+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:45:06.644+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:45:06.657+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.063 seconds
[2025-07-18T22:45:36.784+0000] {processor.py:186} INFO - Started process (PID=1762) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:45:36.785+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:45:36.787+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:45:36.787+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:45:36.796+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:45:36.801+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:45:36.816+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:45:36.816+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:45:36.830+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:45:36.830+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:45:36.840+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.060 seconds
[2025-07-18T22:46:07.059+0000] {processor.py:186} INFO - Started process (PID=1778) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:46:07.060+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:46:07.062+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:46:07.061+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:46:07.070+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:46:07.075+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:46:07.092+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:46:07.092+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:46:07.107+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:46:07.106+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:46:07.117+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.062 seconds
[2025-07-18T22:46:37.532+0000] {processor.py:186} INFO - Started process (PID=1794) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:46:37.532+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:46:37.534+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:46:37.534+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:46:37.542+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:46:37.548+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:46:37.565+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:46:37.565+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:46:37.581+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:46:37.581+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:46:37.593+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.065 seconds
[2025-07-18T22:47:08.270+0000] {processor.py:186} INFO - Started process (PID=1810) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:47:08.271+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:47:08.273+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:47:08.272+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:47:08.282+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:47:08.287+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:47:08.304+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:47:08.303+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:47:08.404+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:47:08.404+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:47:08.415+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.150 seconds
[2025-07-18T22:47:39.448+0000] {processor.py:186} INFO - Started process (PID=1826) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:47:39.449+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:47:39.451+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:47:39.451+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:47:39.459+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:47:39.464+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:47:39.479+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:47:39.479+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:47:39.493+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:47:39.493+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:47:39.504+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.060 seconds
[2025-07-18T22:48:09.921+0000] {processor.py:186} INFO - Started process (PID=1842) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:48:09.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:48:09.923+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:48:09.923+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:48:09.931+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:48:09.937+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:48:09.952+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:48:09.952+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:48:09.966+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:48:09.966+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:48:09.986+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.068 seconds
[2025-07-18T22:48:40.097+0000] {processor.py:186} INFO - Started process (PID=1858) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:48:40.098+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:48:40.099+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:48:40.099+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:48:40.107+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:48:40.113+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:48:40.128+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:48:40.128+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:48:40.143+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:48:40.143+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:48:40.164+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.071 seconds
[2025-07-18T22:49:10.339+0000] {processor.py:186} INFO - Started process (PID=1874) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:49:10.340+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:49:10.342+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:49:10.341+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:49:10.350+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:49:10.355+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:49:10.370+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:49:10.370+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:49:10.385+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:49:10.384+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:49:10.403+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.068 seconds
[2025-07-18T22:49:40.780+0000] {processor.py:186} INFO - Started process (PID=1890) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:49:40.781+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:49:40.782+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:49:40.782+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:49:40.791+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:49:40.797+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:49:40.812+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:49:40.812+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:49:40.916+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:49:40.916+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:49:40.927+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.151 seconds
[2025-07-18T22:50:11.021+0000] {processor.py:186} INFO - Started process (PID=1906) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:50:11.022+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:50:11.024+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:50:11.023+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:50:11.034+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:50:11.040+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:50:11.055+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:50:11.055+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:50:11.069+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:50:11.069+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:50:11.088+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.072 seconds
[2025-07-18T22:50:41.229+0000] {processor.py:186} INFO - Started process (PID=1922) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:50:41.230+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:50:41.232+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:50:41.232+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:50:41.240+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:50:41.246+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:50:41.265+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:50:41.265+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:50:41.281+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:50:41.281+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:50:41.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.069 seconds
[2025-07-18T22:51:11.524+0000] {processor.py:186} INFO - Started process (PID=1930) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:51:11.524+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:51:11.526+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:51:11.526+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:51:11.533+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:51:11.538+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:51:11.553+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:51:11.553+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:51:11.567+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:51:11.567+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:51:11.586+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.066 seconds
[2025-07-18T22:51:42.049+0000] {processor.py:186} INFO - Started process (PID=1946) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:51:42.050+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:51:42.053+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:51:42.053+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:51:42.070+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:51:42.077+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:51:42.092+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:51:42.092+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:51:42.106+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:51:42.106+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:51:42.117+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.074 seconds
[2025-07-18T22:52:12.421+0000] {processor.py:186} INFO - Started process (PID=1963) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:52:12.422+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:52:12.423+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:52:12.423+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:52:12.431+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:52:12.436+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:52:12.451+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:52:12.451+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:52:12.465+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:52:12.465+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:52:12.571+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.154 seconds
[2025-07-18T22:52:43.056+0000] {processor.py:186} INFO - Started process (PID=1979) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:52:43.057+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:52:43.059+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:52:43.059+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:52:43.067+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:52:43.073+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:52:43.088+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:52:43.088+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:52:43.102+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:52:43.102+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:52:43.113+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.062 seconds
[2025-07-18T22:53:13.295+0000] {processor.py:186} INFO - Started process (PID=1995) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:53:13.296+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:53:13.298+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:53:13.297+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:53:13.309+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:53:13.314+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:53:13.330+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:53:13.330+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:53:13.344+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:53:13.344+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:53:13.355+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.066 seconds
[2025-07-18T22:53:43.548+0000] {processor.py:186} INFO - Started process (PID=2011) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:53:43.548+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:53:43.550+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:53:43.550+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:53:43.564+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:53:43.571+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:53:43.588+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:53:43.588+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:53:43.602+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:53:43.602+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:53:43.614+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.070 seconds
[2025-07-18T22:54:13.762+0000] {processor.py:186} INFO - Started process (PID=2027) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:54:13.764+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:54:13.769+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:54:13.769+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:54:13.790+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:54:13.801+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:54:13.820+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:54:13.820+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:54:13.834+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:54:13.834+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:54:13.846+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.103 seconds
[2025-07-18T22:54:44.335+0000] {processor.py:186} INFO - Started process (PID=2043) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:54:44.336+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:54:44.339+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:54:44.339+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:54:44.360+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:54:44.368+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:54:44.387+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:54:44.387+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:54:44.404+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:54:44.403+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:54:44.517+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.186 seconds
[2025-07-18T22:55:14.892+0000] {processor.py:186} INFO - Started process (PID=2059) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:55:14.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:55:14.900+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:55:14.900+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:55:14.927+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:55:14.937+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:55:14.952+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:55:14.952+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:55:15.061+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:55:15.060+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:55:15.081+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.196 seconds
[2025-07-18T22:55:45.361+0000] {processor.py:186} INFO - Started process (PID=2075) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:55:45.362+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:55:45.366+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:55:45.365+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:55:45.383+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:55:45.390+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:55:45.405+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:55:45.405+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:55:45.419+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:55:45.419+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:55:45.439+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.085 seconds
[2025-07-18T22:56:15.564+0000] {processor.py:186} INFO - Started process (PID=2091) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:56:15.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:56:15.567+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:56:15.567+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:56:15.579+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:56:15.585+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:56:15.600+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:56:15.600+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:56:15.614+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:56:15.614+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:56:15.634+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.076 seconds
[2025-07-18T22:56:45.933+0000] {processor.py:186} INFO - Started process (PID=2107) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:56:45.934+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:56:45.935+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:56:45.935+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:56:45.943+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:56:45.948+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:56:45.964+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:56:45.964+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:56:45.978+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:56:45.978+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:56:45.989+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.059 seconds
[2025-07-18T22:57:16.515+0000] {processor.py:186} INFO - Started process (PID=2123) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:57:16.516+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:57:16.518+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:57:16.518+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:57:16.527+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:57:16.532+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:57:16.548+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:57:16.547+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:57:16.562+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:57:16.562+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:57:16.696+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.185 seconds
[2025-07-18T22:57:46.778+0000] {processor.py:186} INFO - Started process (PID=2139) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:57:46.779+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:57:46.781+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:57:46.780+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:57:46.788+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:57:46.794+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:57:46.810+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:57:46.810+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:57:46.925+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:57:46.925+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:57:46.944+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.174 seconds
[2025-07-18T22:58:16.993+0000] {processor.py:186} INFO - Started process (PID=2155) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:58:16.994+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:58:16.995+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:58:16.995+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:58:17.003+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:58:17.009+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:58:17.024+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:58:17.024+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:58:17.039+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:58:17.039+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:58:17.050+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.061 seconds
[2025-07-18T22:58:47.220+0000] {processor.py:186} INFO - Started process (PID=2171) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:58:47.221+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:58:47.222+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:58:47.222+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:58:47.231+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:58:47.237+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:58:47.253+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:58:47.253+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:58:47.268+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:58:47.268+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:58:47.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.063 seconds
[2025-07-18T22:59:17.536+0000] {processor.py:186} INFO - Started process (PID=2187) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:59:17.537+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:59:17.539+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:59:17.538+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:59:17.551+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:59:17.557+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:59:17.572+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:59:17.572+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:59:17.586+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:59:17.586+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:59:17.598+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.066 seconds
[2025-07-18T22:59:47.977+0000] {processor.py:186} INFO - Started process (PID=2203) to work on /opt/airflow/dags/dags.py
[2025-07-18T22:59:47.978+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T22:59:47.981+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:59:47.981+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T22:59:48.047+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T22:59:48.054+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T22:59:48.075+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:59:48.075+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T22:59:48.093+0000] {logging_mixin.py:190} INFO - [2025-07-18T22:59:48.093+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T22:59:48.111+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.139 seconds
[2025-07-18T23:00:18.892+0000] {processor.py:186} INFO - Started process (PID=2219) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:00:18.893+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:00:18.894+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:00:18.894+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:00:18.902+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:00:18.909+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:00:18.926+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:00:18.926+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:00:19.037+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:00:19.037+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:00:19.048+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.161 seconds
[2025-07-18T23:00:49.564+0000] {processor.py:186} INFO - Started process (PID=2235) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:00:49.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:00:49.567+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:00:49.567+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:00:49.606+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:00:49.613+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:00:49.631+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:00:49.631+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:00:49.754+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:00:49.753+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:00:49.768+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.209 seconds
[2025-07-18T23:01:19.862+0000] {processor.py:186} INFO - Started process (PID=2251) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:01:19.862+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:01:19.864+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:01:19.864+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:01:19.872+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:01:19.877+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:01:19.892+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:01:19.892+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:01:19.906+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:01:19.906+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:01:19.917+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.059 seconds
[2025-07-18T23:01:50.075+0000] {processor.py:186} INFO - Started process (PID=2267) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:01:50.077+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:01:50.079+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:01:50.078+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:01:50.087+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:01:50.092+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:01:50.108+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:01:50.108+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:01:50.122+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:01:50.121+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:01:50.132+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.062 seconds
[2025-07-18T23:02:20.560+0000] {processor.py:186} INFO - Started process (PID=2283) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:02:20.562+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:02:20.565+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:02:20.564+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:02:20.578+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:02:20.584+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:02:20.601+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:02:20.601+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:02:20.617+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:02:20.617+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:02:20.716+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.161 seconds
[2025-07-18T23:02:50.983+0000] {processor.py:186} INFO - Started process (PID=2299) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:02:50.984+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:02:50.985+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:02:50.985+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:02:50.995+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:02:51.001+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:02:51.017+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:02:51.017+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:02:51.135+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:02:51.135+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:02:51.149+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.170 seconds
[2025-07-18T23:03:21.380+0000] {processor.py:186} INFO - Started process (PID=2307) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:03:21.381+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:03:21.382+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:03:21.382+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:03:21.390+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:03:21.397+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:03:21.414+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:03:21.414+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:03:21.533+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:03:21.533+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:03:21.544+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.168 seconds
[2025-07-18T23:03:52.349+0000] {processor.py:186} INFO - Started process (PID=2323) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:03:52.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:03:52.352+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:03:52.351+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:03:52.361+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:03:52.369+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:03:52.389+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:03:52.389+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:03:52.408+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:03:52.408+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:03:52.421+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.076 seconds
[2025-07-18T23:04:22.537+0000] {processor.py:186} INFO - Started process (PID=2337) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:04:22.538+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:04:22.540+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:04:22.539+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:04:22.547+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:04:22.553+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:04:22.571+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:04:22.571+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:04:22.587+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:04:22.587+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:04:22.607+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.074 seconds
[2025-07-18T23:04:52.906+0000] {processor.py:186} INFO - Started process (PID=2353) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:04:52.907+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:04:52.909+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:04:52.908+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:04:52.917+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:04:52.922+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:04:52.939+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:04:52.938+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:04:52.954+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:04:52.954+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:04:52.966+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.064 seconds
[2025-07-18T23:05:23.268+0000] {processor.py:186} INFO - Started process (PID=2369) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:05:23.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:05:23.270+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:05:23.270+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:05:23.278+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:05:23.285+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:05:23.301+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:05:23.301+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:05:23.437+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:05:23.437+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:05:23.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.184 seconds
[2025-07-18T23:05:53.835+0000] {processor.py:186} INFO - Started process (PID=2385) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:05:53.836+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:05:53.837+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:05:53.837+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:05:53.845+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:05:53.850+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:05:53.868+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:05:53.868+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:05:53.996+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:05:53.995+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:05:54.006+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.176 seconds
[2025-07-18T23:06:24.168+0000] {processor.py:186} INFO - Started process (PID=2401) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:06:24.168+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:06:24.170+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:06:24.170+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:06:24.178+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:06:24.183+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:06:24.201+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:06:24.201+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:06:24.217+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:06:24.216+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:06:24.228+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.065 seconds
[2025-07-18T23:06:54.399+0000] {processor.py:186} INFO - Started process (PID=2417) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:06:54.400+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:06:54.402+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:06:54.401+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:06:54.410+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:06:54.417+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:06:54.437+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:06:54.437+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:06:54.454+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:06:54.453+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:06:54.465+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.070 seconds
[2025-07-18T23:07:24.700+0000] {processor.py:186} INFO - Started process (PID=2433) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:07:24.700+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:07:24.702+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:07:24.701+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:07:24.712+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:07:24.719+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:07:24.738+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:07:24.737+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:07:24.753+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:07:24.753+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:07:24.766+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.070 seconds
[2025-07-18T23:07:55.077+0000] {processor.py:186} INFO - Started process (PID=2449) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:07:55.078+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:07:55.079+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:07:55.079+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:07:55.088+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:07:55.094+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:07:55.113+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:07:55.113+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:07:55.241+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:07:55.240+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:07:55.251+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.178 seconds
[2025-07-18T23:08:25.599+0000] {processor.py:186} INFO - Started process (PID=2465) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:08:25.599+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:08:25.601+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:08:25.600+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:08:25.609+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:08:25.614+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:08:25.631+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:08:25.631+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:08:25.770+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:08:25.769+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:08:25.782+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.187 seconds
[2025-07-18T23:08:55.988+0000] {processor.py:186} INFO - Started process (PID=2481) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:08:55.989+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:08:55.992+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:08:55.991+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:08:55.999+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:08:56.006+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:08:56.153+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:08:56.153+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:08:56.166+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:08:56.166+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:08:56.177+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.194 seconds
[2025-07-18T23:09:26.289+0000] {processor.py:186} INFO - Started process (PID=2497) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:09:26.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:09:26.291+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:09:26.291+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:09:26.300+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:09:26.307+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:09:26.325+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:09:26.325+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:09:26.345+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:09:26.345+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:09:26.358+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.074 seconds
[2025-07-18T23:09:56.522+0000] {processor.py:186} INFO - Started process (PID=2513) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:09:56.522+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:09:56.524+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:09:56.524+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:09:56.532+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:09:56.538+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:09:56.555+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:09:56.555+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:09:56.569+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:09:56.569+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:09:56.580+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.063 seconds
[2025-07-18T23:10:26.922+0000] {processor.py:186} INFO - Started process (PID=2529) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:10:26.923+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:10:26.925+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:10:26.924+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:10:26.933+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:10:26.939+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:10:26.954+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:10:26.954+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:10:27.081+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:10:27.081+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:10:27.103+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.185 seconds
[2025-07-18T23:10:57.223+0000] {processor.py:186} INFO - Started process (PID=2545) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:10:57.224+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:10:57.225+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:10:57.225+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:10:57.233+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:10:57.238+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:10:57.253+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:10:57.253+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:10:57.380+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:10:57.380+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:10:57.400+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.181 seconds
[2025-07-18T23:11:27.804+0000] {processor.py:186} INFO - Started process (PID=2561) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:11:27.805+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:11:27.807+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:11:27.807+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:11:27.815+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:11:27.820+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:11:27.953+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:11:27.953+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:11:27.967+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:11:27.967+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:11:27.980+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.180 seconds
[2025-07-18T23:11:58.158+0000] {processor.py:186} INFO - Started process (PID=2577) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:11:58.159+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:11:58.161+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:11:58.161+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:11:58.173+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:11:58.179+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:11:58.198+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:11:58.198+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:11:58.216+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:11:58.216+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:11:58.228+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.074 seconds
[2025-07-18T23:12:28.380+0000] {processor.py:186} INFO - Started process (PID=2593) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:12:28.381+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:12:28.382+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:12:28.382+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:12:28.390+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:12:28.397+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:12:28.414+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:12:28.414+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:12:28.430+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:12:28.429+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:12:28.444+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.069 seconds
[2025-07-18T23:12:58.690+0000] {processor.py:186} INFO - Started process (PID=2609) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:12:58.690+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:12:58.692+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:12:58.692+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:12:58.701+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:12:58.707+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:12:58.725+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:12:58.724+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:12:58.740+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:12:58.740+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:12:58.754+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.068 seconds
[2025-07-18T23:13:28.905+0000] {processor.py:186} INFO - Started process (PID=2625) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:13:28.906+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:13:28.908+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:13:28.907+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:13:28.916+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:13:28.921+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:13:28.935+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:13:28.935+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:13:28.949+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:13:28.949+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:13:28.966+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.065 seconds
[2025-07-18T23:13:59.282+0000] {processor.py:186} INFO - Started process (PID=2641) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:13:59.283+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:13:59.285+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:13:59.285+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:13:59.294+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:13:59.301+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:13:59.318+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:13:59.318+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:13:59.333+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:13:59.333+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:13:59.345+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.069 seconds
[2025-07-18T23:14:29.527+0000] {processor.py:186} INFO - Started process (PID=2649) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:14:29.528+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:14:29.529+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:14:29.529+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:14:29.537+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:14:29.543+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:14:29.560+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:14:29.560+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:14:29.575+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:14:29.575+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:14:29.585+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.062 seconds
[2025-07-18T23:14:59.703+0000] {processor.py:186} INFO - Started process (PID=2665) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:14:59.704+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:14:59.706+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:14:59.706+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:14:59.715+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:14:59.722+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:14:59.739+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:14:59.739+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:14:59.755+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:14:59.755+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:14:59.769+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.070 seconds
[2025-07-18T23:15:29.927+0000] {processor.py:186} INFO - Started process (PID=2681) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:15:29.928+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:15:29.930+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:15:29.929+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:15:29.938+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:15:29.945+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:15:29.961+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:15:29.961+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:15:29.977+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:15:29.977+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:15:29.988+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.065 seconds
[2025-07-18T23:16:00.191+0000] {processor.py:186} INFO - Started process (PID=2697) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:16:00.191+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:16:00.193+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:16:00.193+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:16:00.202+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:16:00.208+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:16:00.225+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:16:00.225+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:16:00.242+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:16:00.242+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:16:00.253+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.066 seconds
[2025-07-18T23:16:30.580+0000] {processor.py:186} INFO - Started process (PID=2713) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:16:30.581+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:16:30.582+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:16:30.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:16:30.591+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:16:30.597+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:16:30.613+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:16:30.613+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:16:30.628+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:16:30.628+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:16:30.640+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.064 seconds
[2025-07-18T23:17:00.805+0000] {processor.py:186} INFO - Started process (PID=2729) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:17:00.806+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:17:00.807+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:17:00.807+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:17:00.816+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:17:00.822+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:17:00.839+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:17:00.839+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:17:00.854+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:17:00.854+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:17:00.869+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.068 seconds
[2025-07-18T23:17:30.980+0000] {processor.py:186} INFO - Started process (PID=2745) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:17:30.980+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:17:30.982+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:17:30.982+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:17:31.020+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:17:31.028+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:17:31.049+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:17:31.049+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:17:31.066+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:17:31.066+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:17:31.083+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.108 seconds
[2025-07-18T23:18:01.211+0000] {processor.py:186} INFO - Started process (PID=2761) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:18:01.211+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:18:01.213+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:18:01.213+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:18:01.221+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:18:01.227+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:18:01.243+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:18:01.242+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:18:01.257+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:18:01.256+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:18:01.267+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.061 seconds
[2025-07-18T23:18:31.391+0000] {processor.py:186} INFO - Started process (PID=2777) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:18:31.391+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:18:31.393+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:18:31.393+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:18:31.400+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:18:31.406+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:18:31.423+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:18:31.423+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:18:31.438+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:18:31.438+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:18:31.449+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.063 seconds
[2025-07-18T23:19:01.559+0000] {processor.py:186} INFO - Started process (PID=2793) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:19:01.560+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:19:01.561+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:19:01.561+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:19:01.572+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:19:01.578+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:19:01.593+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:19:01.593+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:19:01.607+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:19:01.607+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:19:01.618+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.063 seconds
[2025-07-18T23:19:32.633+0000] {processor.py:186} INFO - Started process (PID=2809) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:19:32.634+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:19:32.636+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:19:32.636+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:19:32.647+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:19:32.653+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:19:32.672+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:19:32.672+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:19:32.688+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:19:32.687+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:19:32.699+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.070 seconds
[2025-07-18T23:20:02.879+0000] {processor.py:186} INFO - Started process (PID=2825) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:20:02.879+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:20:02.881+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:20:02.881+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:20:02.890+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:20:02.896+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:20:02.911+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:20:02.911+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:20:02.925+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:20:02.925+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:20:02.936+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.062 seconds
[2025-07-18T23:20:33.076+0000] {processor.py:186} INFO - Started process (PID=2841) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:20:33.077+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:20:33.079+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:20:33.078+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:20:33.086+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:20:33.092+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:20:33.108+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:20:33.108+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:20:33.122+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:20:33.122+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:20:33.132+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.061 seconds
[2025-07-18T23:21:03.411+0000] {processor.py:186} INFO - Started process (PID=2857) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:21:03.412+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:21:03.414+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:21:03.414+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:21:03.422+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:21:03.428+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:21:03.443+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:21:03.443+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:21:03.458+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:21:03.458+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:21:03.469+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.062 seconds
[2025-07-18T23:21:34.509+0000] {processor.py:186} INFO - Started process (PID=2873) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:21:34.510+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:21:34.512+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:21:34.511+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:21:34.520+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:21:34.525+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:21:34.541+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:21:34.541+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:21:34.555+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:21:34.555+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:21:34.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.061 seconds
[2025-07-18T23:22:04.842+0000] {processor.py:186} INFO - Started process (PID=2889) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:22:04.843+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:22:04.845+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:22:04.845+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:22:04.857+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:22:04.863+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:22:04.878+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:22:04.878+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:22:04.893+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:22:04.893+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:22:04.904+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.066 seconds
[2025-07-18T23:22:35.158+0000] {processor.py:186} INFO - Started process (PID=2905) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:22:35.165+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:22:35.167+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:22:35.167+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:22:35.175+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:22:35.181+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:22:35.196+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:22:35.196+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:22:35.211+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:22:35.211+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:22:35.223+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.069 seconds
[2025-07-18T23:23:05.463+0000] {processor.py:186} INFO - Started process (PID=2921) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:23:05.463+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:23:05.465+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:23:05.465+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:23:05.478+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:23:05.483+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:23:05.499+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:23:05.499+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:23:05.514+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:23:05.514+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:23:05.525+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.066 seconds
[2025-07-18T23:23:35.885+0000] {processor.py:186} INFO - Started process (PID=2937) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:23:35.887+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:23:35.889+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:23:35.888+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:23:35.977+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:23:35.985+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:23:36.007+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:23:36.006+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:23:36.023+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:23:36.023+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:23:36.040+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.161 seconds
[2025-07-18T23:24:06.175+0000] {processor.py:186} INFO - Started process (PID=2953) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:24:06.176+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:24:06.178+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:24:06.177+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:24:06.187+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:24:06.193+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:24:06.209+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:24:06.209+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:24:06.224+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:24:06.223+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:24:06.234+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.063 seconds
[2025-07-18T23:24:36.327+0000] {processor.py:186} INFO - Started process (PID=2969) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:24:36.328+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:24:36.330+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:24:36.330+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:24:36.338+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:24:36.344+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:24:36.360+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:24:36.360+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:24:36.374+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:24:36.374+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:24:36.385+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.062 seconds
[2025-07-18T23:25:06.729+0000] {processor.py:186} INFO - Started process (PID=2977) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:25:06.730+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:25:06.731+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:25:06.731+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:25:06.741+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:25:06.746+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:25:06.762+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:25:06.762+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:25:06.776+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:25:06.776+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:25:06.787+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.062 seconds
[2025-07-18T23:25:37.123+0000] {processor.py:186} INFO - Started process (PID=2993) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:25:37.125+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:25:37.127+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:25:37.126+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:25:37.221+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:25:37.230+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:25:37.250+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:25:37.249+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:25:37.264+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:25:37.264+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:25:37.274+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.156 seconds
[2025-07-18T23:26:07.370+0000] {processor.py:186} INFO - Started process (PID=3009) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:26:07.371+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:26:07.373+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:26:07.372+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:26:07.382+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:26:07.387+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:26:07.404+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:26:07.404+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:26:07.419+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:26:07.419+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:26:07.429+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.063 seconds
[2025-07-18T23:26:37.696+0000] {processor.py:186} INFO - Started process (PID=3025) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:26:37.697+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:26:37.699+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:26:37.699+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:26:37.706+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:26:37.712+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:26:37.729+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:26:37.729+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:26:37.743+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:26:37.743+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:26:37.754+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.062 seconds
[2025-07-18T23:27:07.974+0000] {processor.py:186} INFO - Started process (PID=3041) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:27:07.974+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:27:07.976+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:27:07.976+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:27:07.990+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:27:07.996+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:27:08.012+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:27:08.012+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:27:08.026+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:27:08.025+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:27:08.036+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.068 seconds
[2025-07-18T23:27:38.280+0000] {processor.py:186} INFO - Started process (PID=3057) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:27:38.280+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:27:38.282+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:27:38.282+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:27:38.290+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:27:38.296+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:27:38.312+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:27:38.312+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:27:38.326+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:27:38.325+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:27:38.336+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.061 seconds
[2025-07-18T23:28:08.482+0000] {processor.py:186} INFO - Started process (PID=3073) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:28:08.483+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:28:08.488+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:28:08.487+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:28:08.495+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:28:08.501+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:28:08.516+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:28:08.516+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:28:08.531+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:28:08.531+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:28:08.541+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.064 seconds
[2025-07-18T23:28:38.703+0000] {processor.py:186} INFO - Started process (PID=3089) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:28:38.703+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:28:38.705+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:28:38.705+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:28:38.715+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:28:38.720+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:28:38.736+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:28:38.736+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:28:38.750+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:28:38.750+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:28:38.760+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.062 seconds
[2025-07-18T23:29:08.880+0000] {processor.py:186} INFO - Started process (PID=3105) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:29:08.880+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:29:08.882+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:29:08.882+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:29:08.890+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:29:08.896+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:29:08.913+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:29:08.913+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:29:08.927+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:29:08.927+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:29:08.938+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.062 seconds
[2025-07-18T23:29:39.235+0000] {processor.py:186} INFO - Started process (PID=3121) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:29:39.238+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:29:39.241+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:29:39.240+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:29:39.299+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:29:39.306+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:29:39.322+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:29:39.322+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:29:39.336+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:29:39.336+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:29:39.346+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.116 seconds
[2025-07-18T23:30:09.627+0000] {processor.py:186} INFO - Started process (PID=3137) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:30:09.628+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:30:09.630+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:30:09.629+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:30:09.639+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:30:09.645+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:30:09.661+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:30:09.661+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:30:09.674+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:30:09.674+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:30:09.685+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.063 seconds
[2025-07-18T23:30:39.869+0000] {processor.py:186} INFO - Started process (PID=3153) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:30:39.870+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:30:39.873+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:30:39.872+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:30:39.932+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:30:39.939+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:30:39.957+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:30:39.956+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:30:39.972+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:30:39.972+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:30:39.989+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.126 seconds
[2025-07-18T23:31:10.131+0000] {processor.py:186} INFO - Started process (PID=3169) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:31:10.132+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:31:10.134+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:31:10.134+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:31:10.147+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:31:10.153+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:31:10.171+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:31:10.171+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:31:10.186+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:31:10.186+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:31:10.201+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.075 seconds
[2025-07-18T23:31:40.487+0000] {processor.py:186} INFO - Started process (PID=3185) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:31:40.487+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:31:40.491+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:31:40.490+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:31:40.561+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:31:40.569+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:31:40.588+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:31:40.587+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:31:40.602+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:31:40.602+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:31:40.617+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.135 seconds
[2025-07-18T23:32:10.833+0000] {processor.py:186} INFO - Started process (PID=3201) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:32:10.834+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:32:10.836+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:32:10.835+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:32:10.844+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:32:10.849+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:32:10.866+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:32:10.865+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:32:10.879+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:32:10.879+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:32:10.889+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.061 seconds
[2025-07-18T23:32:41.182+0000] {processor.py:186} INFO - Started process (PID=3217) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:32:41.183+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:32:41.184+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:32:41.184+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:32:41.193+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:32:41.199+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:32:41.214+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:32:41.214+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:32:41.229+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:32:41.229+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:32:41.241+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.063 seconds
[2025-07-18T23:33:11.365+0000] {processor.py:186} INFO - Started process (PID=3233) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:33:11.366+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:33:11.368+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:33:11.368+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:33:11.376+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:33:11.382+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:33:11.398+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:33:11.398+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:33:11.412+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:33:11.412+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:33:11.424+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.063 seconds
[2025-07-18T23:33:41.689+0000] {processor.py:186} INFO - Started process (PID=3249) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:33:41.690+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:33:41.692+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:33:41.691+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:33:41.699+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:33:41.705+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:33:41.719+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:33:41.719+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:33:41.733+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:33:41.733+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:33:41.743+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.058 seconds
[2025-07-18T23:34:11.888+0000] {processor.py:186} INFO - Started process (PID=3265) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:34:11.889+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:34:11.891+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:34:11.890+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:34:11.903+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:34:11.910+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:34:11.926+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:34:11.926+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:34:11.945+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:34:11.945+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:34:11.974+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.090 seconds
[2025-07-18T23:34:42.109+0000] {processor.py:186} INFO - Started process (PID=3281) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:34:42.110+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:34:42.111+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:34:42.111+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:34:42.119+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:34:42.124+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:34:42.140+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:34:42.139+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:34:42.154+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:34:42.153+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:34:42.165+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.060 seconds
[2025-07-18T23:35:12.456+0000] {processor.py:186} INFO - Started process (PID=3297) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:35:12.457+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:35:12.459+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:35:12.459+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:35:12.478+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:35:12.484+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:35:12.500+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:35:12.500+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:35:12.515+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:35:12.515+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:35:12.526+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.075 seconds
[2025-07-18T23:35:42.736+0000] {processor.py:186} INFO - Started process (PID=3305) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:35:42.737+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:35:42.739+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:35:42.739+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:35:42.747+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:35:42.752+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:35:42.769+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:35:42.769+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:35:42.783+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:35:42.782+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:35:42.794+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.062 seconds
[2025-07-18T23:36:12.975+0000] {processor.py:186} INFO - Started process (PID=3321) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:36:12.976+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:36:12.977+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:36:12.977+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:36:12.986+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:36:12.992+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:36:13.009+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:36:13.009+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:36:13.026+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:36:13.026+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:36:13.038+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.067 seconds
[2025-07-18T23:36:43.150+0000] {processor.py:186} INFO - Started process (PID=3335) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:36:43.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:36:43.153+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:36:43.153+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:36:43.161+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:36:43.166+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:36:43.184+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:36:43.184+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:36:43.200+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:36:43.200+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:36:43.211+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.065 seconds
[2025-07-18T23:37:13.289+0000] {processor.py:186} INFO - Started process (PID=3351) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:37:13.289+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:37:13.291+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:37:13.291+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:37:13.298+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:37:13.305+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:37:13.320+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:37:13.320+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:37:13.334+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:37:13.334+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:37:13.345+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.060 seconds
[2025-07-18T23:37:43.464+0000] {processor.py:186} INFO - Started process (PID=3367) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:37:43.465+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:37:43.467+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:37:43.467+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:37:43.474+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:37:43.480+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:37:43.495+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:37:43.495+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:37:43.509+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:37:43.509+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:37:43.523+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.063 seconds
[2025-07-18T23:38:13.680+0000] {processor.py:186} INFO - Started process (PID=3383) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:38:13.680+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:38:13.682+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:38:13.682+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:38:13.690+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:38:13.697+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:38:13.716+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:38:13.716+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:38:13.734+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:38:13.734+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:38:13.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.076 seconds
[2025-07-18T23:38:43.856+0000] {processor.py:186} INFO - Started process (PID=3399) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:38:43.857+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:38:43.858+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:38:43.858+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:38:43.867+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:38:43.873+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:38:43.889+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:38:43.889+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:38:43.903+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:38:43.903+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:38:43.914+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.062 seconds
[2025-07-18T23:39:14.210+0000] {processor.py:186} INFO - Started process (PID=3415) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:39:14.211+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:39:14.213+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:39:14.213+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:39:14.222+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:39:14.227+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:39:14.243+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:39:14.243+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:39:14.257+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:39:14.257+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:39:14.267+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.061 seconds
[2025-07-18T23:39:44.413+0000] {processor.py:186} INFO - Started process (PID=3431) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:39:44.414+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:39:44.416+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:39:44.416+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:39:44.423+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:39:44.429+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:39:44.445+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:39:44.445+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:39:44.459+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:39:44.459+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:39:44.470+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.061 seconds
[2025-07-18T23:40:14.772+0000] {processor.py:186} INFO - Started process (PID=3447) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:40:14.773+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:40:14.774+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:40:14.774+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:40:14.783+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:40:14.790+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:40:14.808+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:40:14.808+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:40:14.824+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:40:14.824+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:40:14.835+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.068 seconds
[2025-07-18T23:40:45.177+0000] {processor.py:186} INFO - Started process (PID=3463) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:40:45.178+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:40:45.184+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:40:45.183+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:40:45.193+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:40:45.199+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:40:45.214+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:40:45.214+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:40:45.229+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:40:45.229+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:40:45.241+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.068 seconds
[2025-07-18T23:41:16.250+0000] {processor.py:186} INFO - Started process (PID=3479) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:41:16.250+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:41:16.252+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:41:16.252+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:41:16.260+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:41:16.266+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:41:16.283+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:41:16.283+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:41:16.298+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:41:16.298+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:41:16.308+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.063 seconds
[2025-07-18T23:41:46.797+0000] {processor.py:186} INFO - Started process (PID=3495) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:41:46.797+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:41:46.800+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:41:46.799+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:41:46.808+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:41:46.814+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:41:46.829+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:41:46.829+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:41:46.843+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:41:46.843+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:41:46.854+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.061 seconds
[2025-07-18T23:42:16.970+0000] {processor.py:186} INFO - Started process (PID=3511) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:42:16.970+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:42:16.972+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:42:16.972+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:42:16.982+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:42:16.988+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:42:17.004+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:42:17.003+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:42:17.018+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:42:17.018+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:42:17.028+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.064 seconds
[2025-07-18T23:42:47.496+0000] {processor.py:186} INFO - Started process (PID=3527) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:42:47.497+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:42:47.499+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:42:47.499+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:42:47.510+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:42:47.516+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:42:47.532+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:42:47.532+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:42:47.546+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:42:47.546+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:42:47.557+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.065 seconds
[2025-07-18T23:43:17.762+0000] {processor.py:186} INFO - Started process (PID=3543) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:43:17.763+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:43:17.765+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:43:17.765+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:43:17.773+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:43:17.779+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:43:17.795+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:43:17.794+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:43:17.809+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:43:17.809+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:43:17.820+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.062 seconds
[2025-07-18T23:43:48.069+0000] {processor.py:186} INFO - Started process (PID=3559) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:43:48.070+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:43:48.071+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:43:48.071+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:43:48.080+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:43:48.086+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:43:48.101+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:43:48.100+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:43:48.115+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:43:48.115+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:43:48.126+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.061 seconds
[2025-07-18T23:44:18.393+0000] {processor.py:186} INFO - Started process (PID=3575) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:44:18.393+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:44:18.395+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:44:18.395+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:44:18.403+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:44:18.409+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:44:18.425+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:44:18.425+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:44:18.440+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:44:18.440+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:44:18.452+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.063 seconds
[2025-07-18T23:44:48.816+0000] {processor.py:186} INFO - Started process (PID=3591) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:44:48.817+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:44:48.818+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:44:48.818+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:44:48.827+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:44:48.833+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:44:48.849+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:44:48.848+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:44:48.863+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:44:48.862+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:44:48.873+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.062 seconds
[2025-07-18T23:45:19.921+0000] {processor.py:186} INFO - Started process (PID=3607) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:45:19.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:45:19.924+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:45:19.923+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:45:19.931+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:45:19.937+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:45:19.953+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:45:19.952+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:45:19.967+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:45:19.967+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:45:19.977+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.061 seconds
[2025-07-18T23:45:50.149+0000] {processor.py:186} INFO - Started process (PID=3623) to work on /opt/airflow/dags/dags.py
[2025-07-18T23:45:50.150+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-18T23:45:50.156+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:45:50.155+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-18T23:45:50.164+0000] {logging_mixin.py:190} INFO - PySpark is not available
[2025-07-18T23:45:50.170+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-18T23:45:50.185+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:45:50.185+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-07-18T23:45:50.199+0000] {logging_mixin.py:190} INFO - [2025-07-18T23:45:50.199+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-07-17 00:00:00+00:00, run_after=2025-07-18 00:00:00+00:00
[2025-07-18T23:45:50.210+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/dags.py took 0.066 seconds
