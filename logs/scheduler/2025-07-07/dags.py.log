[2025-07-07T21:39:27.041+0000] {processor.py:161} INFO - Started process (PID=201) to work on /opt/airflow/dags/dags.py
[2025-07-07T21:39:27.042+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T21:39:27.043+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:39:27.043+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T21:39:27.124+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T21:39:27.251+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:39:27.239+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T21:39:27.253+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T21:39:27.265+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.226 seconds
[2025-07-07T21:49:53.101+0000] {processor.py:161} INFO - Started process (PID=201) to work on /opt/airflow/dags/dags.py
[2025-07-07T21:49:53.102+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T21:49:53.103+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:49:53.102+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T21:49:53.202+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T21:49:53.341+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:49:53.338+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T21:49:53.341+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T21:49:53.354+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.255 seconds
[2025-07-07T21:50:23.680+0000] {processor.py:161} INFO - Started process (PID=220) to work on /opt/airflow/dags/dags.py
[2025-07-07T21:50:23.681+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T21:50:23.683+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:50:23.682+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T21:50:23.840+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T21:50:24.010+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:50:23.998+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T21:50:24.013+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T21:50:24.037+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.360 seconds
[2025-07-07T21:50:54.335+0000] {processor.py:161} INFO - Started process (PID=239) to work on /opt/airflow/dags/dags.py
[2025-07-07T21:50:54.336+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T21:50:54.340+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:50:54.340+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T21:50:54.492+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T21:50:54.651+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:50:54.643+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T21:50:54.652+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T21:50:54.671+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.339 seconds
[2025-07-07T21:51:25.079+0000] {processor.py:161} INFO - Started process (PID=258) to work on /opt/airflow/dags/dags.py
[2025-07-07T21:51:25.081+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T21:51:25.085+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:51:25.085+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T21:51:25.243+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T21:51:25.392+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:51:25.384+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T21:51:25.394+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T21:51:25.410+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.337 seconds
[2025-07-07T21:51:55.657+0000] {processor.py:161} INFO - Started process (PID=277) to work on /opt/airflow/dags/dags.py
[2025-07-07T21:51:55.658+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T21:51:55.659+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:51:55.658+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T21:51:55.710+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T21:51:55.847+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:51:55.841+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T21:51:55.849+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T21:51:55.873+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.219 seconds
[2025-07-07T21:52:26.127+0000] {processor.py:161} INFO - Started process (PID=296) to work on /opt/airflow/dags/dags.py
[2025-07-07T21:52:26.128+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T21:52:26.129+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:52:26.129+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T21:52:26.181+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T21:52:26.312+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:52:26.297+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T21:52:26.315+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T21:52:26.348+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.225 seconds
[2025-07-07T21:52:56.467+0000] {processor.py:161} INFO - Started process (PID=315) to work on /opt/airflow/dags/dags.py
[2025-07-07T21:52:56.468+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T21:52:56.469+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:52:56.469+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T21:52:56.516+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T21:52:56.646+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:52:56.632+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T21:52:56.649+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T21:52:56.679+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.215 seconds
[2025-07-07T21:53:26.830+0000] {processor.py:161} INFO - Started process (PID=334) to work on /opt/airflow/dags/dags.py
[2025-07-07T21:53:26.831+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T21:53:26.831+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:53:26.831+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T21:53:26.874+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T21:53:26.989+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:53:26.986+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T21:53:26.990+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T21:53:27.011+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.184 seconds
[2025-07-07T21:53:57.362+0000] {processor.py:161} INFO - Started process (PID=353) to work on /opt/airflow/dags/dags.py
[2025-07-07T21:53:57.363+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T21:53:57.363+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:53:57.363+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T21:53:57.410+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T21:53:57.527+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:53:57.523+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T21:53:57.529+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T21:53:57.557+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.197 seconds
[2025-07-07T21:54:27.705+0000] {processor.py:161} INFO - Started process (PID=372) to work on /opt/airflow/dags/dags.py
[2025-07-07T21:54:27.706+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T21:54:27.707+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:54:27.707+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T21:54:27.755+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T21:54:27.880+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:54:27.870+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T21:54:27.882+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T21:54:27.905+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.203 seconds
[2025-07-07T21:54:58.100+0000] {processor.py:161} INFO - Started process (PID=391) to work on /opt/airflow/dags/dags.py
[2025-07-07T21:54:58.101+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T21:54:58.102+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:54:58.102+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T21:54:58.179+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T21:54:58.301+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:54:58.299+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T21:54:58.302+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T21:54:58.315+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.219 seconds
[2025-07-07T21:55:28.420+0000] {processor.py:161} INFO - Started process (PID=410) to work on /opt/airflow/dags/dags.py
[2025-07-07T21:55:28.421+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T21:55:28.421+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:55:28.421+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T21:55:28.469+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T21:55:28.586+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:55:28.581+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T21:55:28.588+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T21:55:28.616+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.198 seconds
[2025-07-07T21:55:58.880+0000] {processor.py:161} INFO - Started process (PID=429) to work on /opt/airflow/dags/dags.py
[2025-07-07T21:55:58.881+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T21:55:58.881+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:55:58.881+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T21:55:58.930+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T21:55:59.063+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:55:59.049+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T21:55:59.065+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T21:55:59.092+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.216 seconds
[2025-07-07T21:56:29.265+0000] {processor.py:161} INFO - Started process (PID=448) to work on /opt/airflow/dags/dags.py
[2025-07-07T21:56:29.266+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T21:56:29.267+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:56:29.267+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T21:56:29.323+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T21:56:29.437+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:56:29.435+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T21:56:29.438+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T21:56:29.452+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.190 seconds
[2025-07-07T21:56:59.650+0000] {processor.py:161} INFO - Started process (PID=467) to work on /opt/airflow/dags/dags.py
[2025-07-07T21:56:59.651+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T21:56:59.652+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:56:59.652+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T21:56:59.700+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T21:56:59.824+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:56:59.816+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T21:56:59.826+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T21:56:59.864+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.218 seconds
[2025-07-07T21:57:29.935+0000] {processor.py:161} INFO - Started process (PID=486) to work on /opt/airflow/dags/dags.py
[2025-07-07T21:57:29.936+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T21:57:29.937+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:57:29.937+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T21:57:29.995+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T21:57:30.113+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:57:30.110+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T21:57:30.113+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T21:57:30.130+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.198 seconds
[2025-07-07T21:58:00.515+0000] {processor.py:161} INFO - Started process (PID=505) to work on /opt/airflow/dags/dags.py
[2025-07-07T21:58:00.516+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T21:58:00.517+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:58:00.517+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T21:58:00.573+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T21:58:00.709+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:58:00.690+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T21:58:00.715+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T21:58:00.742+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.229 seconds
[2025-07-07T21:58:30.900+0000] {processor.py:161} INFO - Started process (PID=524) to work on /opt/airflow/dags/dags.py
[2025-07-07T21:58:30.902+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T21:58:30.904+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:58:30.904+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T21:58:30.961+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T21:58:31.079+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:58:31.074+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T21:58:31.081+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T21:58:31.128+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.231 seconds
[2025-07-07T21:59:01.354+0000] {processor.py:161} INFO - Started process (PID=543) to work on /opt/airflow/dags/dags.py
[2025-07-07T21:59:01.356+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T21:59:01.359+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:59:01.358+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T21:59:01.480+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T21:59:01.626+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:59:01.624+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T21:59:01.627+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T21:59:01.640+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.289 seconds
[2025-07-07T21:59:31.927+0000] {processor.py:161} INFO - Started process (PID=562) to work on /opt/airflow/dags/dags.py
[2025-07-07T21:59:31.929+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T21:59:31.930+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:59:31.930+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T21:59:32.040+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T21:59:32.184+0000] {logging_mixin.py:188} INFO - [2025-07-07T21:59:32.181+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T21:59:32.184+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T21:59:32.202+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.278 seconds
[2025-07-07T22:00:02.602+0000] {processor.py:161} INFO - Started process (PID=581) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:00:02.603+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:00:02.605+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:00:02.604+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:00:02.654+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:00:02.774+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:00:02.768+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:00:02.775+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:00:02.794+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.195 seconds
[2025-07-07T22:00:33.077+0000] {processor.py:161} INFO - Started process (PID=600) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:00:33.079+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:00:33.080+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:00:33.079+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:00:33.206+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:00:33.355+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:00:33.348+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:00:33.356+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:00:33.379+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.305 seconds
[2025-07-07T22:01:03.628+0000] {processor.py:161} INFO - Started process (PID=619) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:01:03.630+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:01:03.631+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:01:03.631+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:01:03.725+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:01:03.862+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:01:03.854+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:01:03.863+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:01:03.879+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.253 seconds
[2025-07-07T22:01:34.137+0000] {processor.py:161} INFO - Started process (PID=638) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:01:34.138+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:01:34.138+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:01:34.138+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:01:34.189+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:01:34.313+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:01:34.302+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:01:34.314+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:01:34.333+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.200 seconds
[2025-07-07T22:02:04.539+0000] {processor.py:161} INFO - Started process (PID=657) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:02:04.540+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:02:04.540+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:02:04.540+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:02:04.594+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:02:04.716+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:02:04.710+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:02:04.717+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:02:04.738+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.202 seconds
[2025-07-07T22:02:35.000+0000] {processor.py:161} INFO - Started process (PID=676) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:02:35.001+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:02:35.002+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:02:35.002+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:02:35.055+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:02:35.183+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:02:35.174+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:02:35.188+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:02:35.233+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.236 seconds
[2025-07-07T22:03:05.607+0000] {processor.py:161} INFO - Started process (PID=695) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:03:05.608+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:03:05.609+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:03:05.609+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:03:05.660+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:03:05.789+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:03:05.776+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:03:05.792+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:03:05.831+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.226 seconds
[2025-07-07T22:03:36.009+0000] {processor.py:161} INFO - Started process (PID=714) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:03:36.009+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:03:36.010+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:03:36.010+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:03:36.057+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:03:36.172+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:03:36.169+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:03:36.173+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:03:36.193+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.187 seconds
[2025-07-07T22:04:06.464+0000] {processor.py:161} INFO - Started process (PID=733) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:04:06.465+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:04:06.469+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:04:06.469+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:04:06.581+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:04:06.698+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:04:06.696+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:04:06.698+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:04:06.711+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.249 seconds
[2025-07-07T22:04:37.025+0000] {processor.py:161} INFO - Started process (PID=752) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:04:37.027+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:04:37.029+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:04:37.029+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:04:37.187+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:04:37.331+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:04:37.323+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:04:37.333+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:04:37.350+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.327 seconds
[2025-07-07T22:05:07.657+0000] {processor.py:161} INFO - Started process (PID=771) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:05:07.659+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:05:07.660+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:05:07.659+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:05:07.716+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:05:07.832+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:05:07.830+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:05:07.832+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:05:07.848+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.194 seconds
[2025-07-07T22:05:38.116+0000] {processor.py:161} INFO - Started process (PID=790) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:05:38.117+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:05:38.118+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:05:38.118+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:05:38.246+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:05:38.387+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:05:38.380+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:05:38.388+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:05:38.408+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.294 seconds
[2025-07-07T22:06:08.641+0000] {processor.py:161} INFO - Started process (PID=810) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:06:08.642+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:06:08.643+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:06:08.643+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:06:08.728+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:06:08.850+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:06:08.843+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:06:08.851+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:06:08.872+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.233 seconds
[2025-07-07T22:06:38.996+0000] {processor.py:161} INFO - Started process (PID=829) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:06:38.997+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:06:38.997+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:06:38.997+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:06:39.045+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:06:39.173+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:06:39.160+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:06:39.178+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:06:39.218+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.224 seconds
[2025-07-07T22:07:09.488+0000] {processor.py:161} INFO - Started process (PID=848) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:07:09.489+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:07:09.490+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:07:09.490+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:07:09.560+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:07:09.686+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:07:09.681+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:07:09.687+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:07:09.704+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.218 seconds
[2025-07-07T22:07:39.975+0000] {processor.py:161} INFO - Started process (PID=867) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:07:39.977+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:07:39.981+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:07:39.981+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:07:40.125+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:07:40.291+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:07:40.281+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:07:40.293+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:07:40.338+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.368 seconds
[2025-07-07T22:08:10.716+0000] {processor.py:161} INFO - Started process (PID=886) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:08:10.717+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:08:10.720+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:08:10.720+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:08:10.858+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:08:11.003+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:08:11.001+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:08:11.004+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:08:11.019+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.308 seconds
[2025-07-07T22:08:41.309+0000] {processor.py:161} INFO - Started process (PID=905) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:08:41.310+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:08:41.312+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:08:41.312+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:08:41.390+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:08:41.506+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:08:41.502+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:08:41.507+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:08:41.522+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.217 seconds
[2025-07-07T22:09:11.776+0000] {processor.py:161} INFO - Started process (PID=924) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:09:11.777+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:09:11.778+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:09:11.778+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:09:11.842+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:09:11.964+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:09:11.961+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:09:11.965+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:09:11.980+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.206 seconds
[2025-07-07T22:09:42.104+0000] {processor.py:161} INFO - Started process (PID=943) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:09:42.105+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:09:42.106+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:09:42.106+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:09:42.155+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:09:42.272+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:09:42.267+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:09:42.273+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:09:42.289+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.189 seconds
[2025-07-07T22:10:12.751+0000] {processor.py:161} INFO - Started process (PID=962) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:10:12.752+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:10:12.753+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:10:12.752+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:10:12.847+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:10:12.967+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:10:12.962+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:10:12.968+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:10:12.982+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.233 seconds
[2025-07-07T22:10:43.228+0000] {processor.py:161} INFO - Started process (PID=981) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:10:43.229+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:10:43.230+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:10:43.230+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:10:43.295+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:10:43.417+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:10:43.412+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:10:43.418+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:10:43.433+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.207 seconds
[2025-07-07T22:11:13.481+0000] {processor.py:161} INFO - Started process (PID=1000) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:11:13.482+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:11:13.484+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:11:13.483+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:11:13.554+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:11:13.671+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:11:13.669+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:11:13.672+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:11:13.687+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.209 seconds
[2025-07-07T22:11:43.948+0000] {processor.py:161} INFO - Started process (PID=1019) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:11:43.949+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:11:43.950+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:11:43.950+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:11:44.053+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:11:44.202+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:11:44.191+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:11:44.203+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:11:44.217+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.271 seconds
[2025-07-07T22:12:14.501+0000] {processor.py:161} INFO - Started process (PID=1038) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:12:14.503+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:12:14.505+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:12:14.504+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:12:14.589+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:12:14.716+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:12:14.703+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:12:14.718+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:12:14.748+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.251 seconds
[2025-07-07T22:12:44.783+0000] {processor.py:161} INFO - Started process (PID=1057) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:12:44.784+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:12:44.785+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:12:44.785+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:12:44.889+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:12:45.020+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:12:45.017+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:12:45.020+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:12:45.034+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.254 seconds
[2025-07-07T22:13:15.261+0000] {processor.py:161} INFO - Started process (PID=1076) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:13:15.262+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:13:15.263+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:13:15.263+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:13:15.322+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:13:15.452+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:13:15.442+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:13:15.454+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:13:15.477+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.219 seconds
[2025-07-07T22:13:45.766+0000] {processor.py:161} INFO - Started process (PID=1095) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:13:45.768+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:13:45.770+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:13:45.769+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:13:45.892+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:13:46.032+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:13:46.023+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:13:46.034+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:13:46.052+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.290 seconds
[2025-07-07T22:14:16.335+0000] {processor.py:161} INFO - Started process (PID=1114) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:14:16.337+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:14:16.338+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:14:16.338+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:14:16.426+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:14:16.591+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:14:16.581+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:14:16.593+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:14:16.610+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.277 seconds
[2025-07-07T22:14:46.905+0000] {processor.py:161} INFO - Started process (PID=1133) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:14:46.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:14:46.908+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:14:46.907+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:14:46.983+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:14:47.113+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:14:47.101+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:14:47.114+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:14:47.141+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.240 seconds
[2025-07-07T22:15:17.329+0000] {processor.py:161} INFO - Started process (PID=1152) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:15:17.330+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:15:17.331+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:15:17.331+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:15:17.403+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:15:17.523+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:15:17.519+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 5, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2025-07-07T22:15:17.524+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:15:17.561+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.234 seconds
[2025-07-07T22:15:30.491+0000] {processor.py:161} INFO - Started process (PID=1171) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:15:30.492+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:15:30.493+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:15:30.493+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:15:30.650+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:15:30.683+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:15:30.674+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'C:\\spark/./bin/spark-submit'
[2025-07-07T22:15:30.685+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:15:30.700+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.211 seconds
[2025-07-07T22:15:53.901+0000] {processor.py:161} INFO - Started process (PID=1183) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:15:53.902+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:15:53.903+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:15:53.902+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:15:54.055+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:15:54.068+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:15:54.067+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'C:\\spark/./bin/spark-submit'
[2025-07-07T22:15:54.069+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:15:54.083+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.184 seconds
[2025-07-07T22:15:58.964+0000] {processor.py:161} INFO - Started process (PID=1189) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:15:58.965+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:15:58.965+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:15:58.965+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:15:59.059+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:15:59.074+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:15:59.072+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'C:\\spark/./bin/spark-submit'
[2025-07-07T22:15:59.074+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:15:59.090+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.128 seconds
[2025-07-07T22:16:00.133+0000] {processor.py:161} INFO - Started process (PID=1195) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:16:00.134+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:16:00.135+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:16:00.134+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:16:00.265+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:16:00.291+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:16:00.280+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'C:\\spark/./bin/spark-submit'
[2025-07-07T22:16:00.292+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:16:00.306+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.176 seconds
[2025-07-07T22:16:08.453+0000] {processor.py:161} INFO - Started process (PID=1201) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:16:08.455+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:16:08.457+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:16:08.457+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:16:08.628+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:16:08.658+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:16:08.654+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'C:\\spark/./bin/spark-submit'
[2025-07-07T22:16:08.659+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:16:08.674+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.223 seconds
[2025-07-07T22:16:10.460+0000] {processor.py:161} INFO - Started process (PID=1207) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:16:10.461+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:16:10.462+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:16:10.462+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:16:10.619+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:16:10.665+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:16:10.655+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'C:\\spark/./bin/spark-submit'
[2025-07-07T22:16:10.667+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:16:10.686+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.229 seconds
[2025-07-07T22:16:41.013+0000] {processor.py:161} INFO - Started process (PID=1219) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:16:41.015+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:16:41.017+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:16:41.017+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:16:41.163+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:16:41.195+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:16:41.193+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'C:\\spark/./bin/spark-submit'
[2025-07-07T22:16:41.195+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:16:41.209+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.199 seconds
[2025-07-07T22:17:15.190+0000] {processor.py:161} INFO - Started process (PID=201) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:17:15.191+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:17:15.192+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:17:15.191+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:17:15.252+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:17:15.284+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:17:15.281+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'C:\\spark/./bin/spark-submit'
[2025-07-07T22:17:15.286+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:17:15.309+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.121 seconds
[2025-07-07T22:17:45.407+0000] {processor.py:161} INFO - Started process (PID=213) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:17:45.408+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:17:45.409+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:17:45.408+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:17:45.519+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:17:45.558+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:17:45.551+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'C:\\spark/./bin/spark-submit'
[2025-07-07T22:17:45.558+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:17:45.574+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.169 seconds
[2025-07-07T22:18:15.917+0000] {processor.py:161} INFO - Started process (PID=225) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:18:15.918+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:18:15.918+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:18:15.918+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:18:16.056+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:18:16.102+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:18:16.098+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'C:\\spark/./bin/spark-submit'
[2025-07-07T22:18:16.102+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:18:16.115+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.201 seconds
[2025-07-07T22:18:45.082+0000] {processor.py:161} INFO - Started process (PID=237) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:18:45.083+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:18:45.083+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:18:45.083+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:18:45.165+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:18:45.181+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:18:45.179+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:18:45.182+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:18:45.196+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.117 seconds
[2025-07-07T22:18:48.168+0000] {processor.py:161} INFO - Started process (PID=243) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:18:48.169+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:18:48.170+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:18:48.169+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:18:48.227+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:18:48.240+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:18:48.238+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:18:48.240+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:18:48.262+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.097 seconds
[2025-07-07T22:19:18.513+0000] {processor.py:161} INFO - Started process (PID=255) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:19:18.514+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:19:18.518+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:19:18.518+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:19:18.569+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:19:18.584+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:19:18.582+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:19:18.584+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:19:18.597+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.086 seconds
[2025-07-07T22:19:48.812+0000] {processor.py:161} INFO - Started process (PID=267) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:19:48.813+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:19:48.815+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:19:48.815+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:19:48.956+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:19:49.006+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:19:48.999+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:19:49.007+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:19:49.025+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.216 seconds
[2025-07-07T22:20:19.315+0000] {processor.py:161} INFO - Started process (PID=279) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:20:19.316+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:20:19.317+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:20:19.317+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:20:19.366+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:20:19.380+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:20:19.378+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:20:19.380+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:20:19.394+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.081 seconds
[2025-07-07T22:20:49.494+0000] {processor.py:161} INFO - Started process (PID=291) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:20:49.495+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:20:49.495+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:20:49.495+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:20:49.548+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:20:49.567+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:20:49.561+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:20:49.568+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:20:49.581+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.090 seconds
[2025-07-07T22:21:19.864+0000] {processor.py:161} INFO - Started process (PID=303) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:21:19.866+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:21:19.867+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:21:19.866+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:21:19.918+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:21:19.934+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:21:19.932+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = pyspark.sql.SparkSession\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:21:19.934+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:21:19.946+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.085 seconds
[2025-07-07T22:21:50.111+0000] {processor.py:161} INFO - Started process (PID=315) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:21:50.112+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:21:50.114+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:21:50.113+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:21:50.219+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:21:50.233+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:21:50.231+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:21:50.233+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:21:50.245+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.137 seconds
[2025-07-07T22:22:21.264+0000] {processor.py:161} INFO - Started process (PID=201) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:22:21.265+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:22:21.266+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:22:21.266+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:22:21.323+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:22:21.359+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:22:21.356+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:22:21.360+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:22:21.378+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.116 seconds
[2025-07-07T22:22:51.529+0000] {processor.py:161} INFO - Started process (PID=213) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:22:51.530+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:22:51.531+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:22:51.530+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:22:51.585+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:22:51.646+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:22:51.633+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:22:51.648+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:22:51.662+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.138 seconds
[2025-07-07T22:23:21.790+0000] {processor.py:161} INFO - Started process (PID=225) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:23:21.791+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:23:21.791+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:23:21.791+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:23:21.872+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:23:21.902+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:23:21.897+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:23:21.903+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:23:21.915+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.128 seconds
[2025-07-07T22:23:52.101+0000] {processor.py:161} INFO - Started process (PID=237) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:23:52.102+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:23:52.103+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:23:52.103+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:23:52.158+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:23:52.170+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:23:52.169+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:23:52.171+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:23:52.183+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.085 seconds
[2025-07-07T22:24:22.595+0000] {processor.py:161} INFO - Started process (PID=249) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:24:22.596+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:24:22.597+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:24:22.596+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:24:22.685+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:24:22.699+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:24:22.697+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:24:22.701+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:24:22.715+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.122 seconds
[2025-07-07T22:24:52.820+0000] {processor.py:161} INFO - Started process (PID=261) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:24:52.823+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:24:52.827+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:24:52.827+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:24:52.954+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:24:53.016+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:24:53.006+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:24:53.017+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:24:53.037+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.219 seconds
[2025-07-07T22:25:23.205+0000] {processor.py:161} INFO - Started process (PID=273) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:25:23.206+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:25:23.206+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:25:23.206+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:25:23.260+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:25:23.275+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:25:23.273+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:25:23.275+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:25:23.289+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.086 seconds
[2025-07-07T22:25:53.517+0000] {processor.py:161} INFO - Started process (PID=285) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:25:53.518+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:25:53.518+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:25:53.518+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:25:53.571+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:25:53.598+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:25:53.585+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:25:53.599+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:25:53.612+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.097 seconds
[2025-07-07T22:26:23.801+0000] {processor.py:161} INFO - Started process (PID=297) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:26:23.802+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:26:23.803+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:26:23.802+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:26:23.906+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:26:23.941+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:26:23.937+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:26:23.942+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:26:23.958+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.160 seconds
[2025-07-07T22:26:54.060+0000] {processor.py:161} INFO - Started process (PID=309) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:26:54.061+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:26:54.062+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:26:54.061+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:26:54.125+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:26:54.142+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:26:54.140+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:26:54.142+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:26:54.158+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.101 seconds
[2025-07-07T22:27:24.797+0000] {processor.py:161} INFO - Started process (PID=321) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:27:24.798+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:27:24.804+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:27:24.804+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:27:24.893+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:27:24.927+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:27:24.925+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:27:24.928+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:27:24.945+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.150 seconds
[2025-07-07T22:27:55.033+0000] {processor.py:161} INFO - Started process (PID=333) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:27:55.035+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:27:55.035+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:27:55.035+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:27:55.126+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:27:55.148+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:27:55.145+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:27:55.149+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:27:55.169+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.138 seconds
[2025-07-07T22:28:25.419+0000] {processor.py:161} INFO - Started process (PID=345) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:28:25.420+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:28:25.423+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:28:25.422+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:28:25.539+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:28:25.555+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:28:25.553+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:28:25.555+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:28:25.571+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.155 seconds
[2025-07-07T22:28:55.713+0000] {processor.py:161} INFO - Started process (PID=357) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:28:55.715+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:28:55.717+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:28:55.717+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:28:55.784+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:28:55.800+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:28:55.798+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:28:55.801+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:28:55.817+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.107 seconds
[2025-07-07T22:29:25.940+0000] {processor.py:161} INFO - Started process (PID=369) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:29:25.941+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:29:25.942+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:29:25.941+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:29:25.997+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:29:26.013+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:29:26.011+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:29:26.014+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:29:26.030+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.093 seconds
[2025-07-07T22:29:56.182+0000] {processor.py:161} INFO - Started process (PID=381) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:29:56.183+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:29:56.183+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:29:56.183+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:29:56.231+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:29:56.246+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:29:56.244+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:29:56.247+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:29:56.261+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.081 seconds
[2025-07-07T22:30:26.544+0000] {processor.py:161} INFO - Started process (PID=393) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:30:26.547+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:30:26.549+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:30:26.549+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:30:26.685+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:30:26.701+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:30:26.699+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:30:26.702+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:30:26.717+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.175 seconds
[2025-07-07T22:30:56.832+0000] {processor.py:161} INFO - Started process (PID=405) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:30:56.833+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:30:56.834+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:30:56.833+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:30:56.883+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:30:56.906+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:30:56.895+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:30:56.908+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:30:56.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.094 seconds
[2025-07-07T22:31:27.209+0000] {processor.py:161} INFO - Started process (PID=417) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:31:27.210+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:31:27.212+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:31:27.212+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:31:27.340+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:31:27.394+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:31:27.382+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:31:27.396+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:31:27.420+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.214 seconds
[2025-07-07T22:31:57.702+0000] {processor.py:161} INFO - Started process (PID=429) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:31:57.703+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:31:57.704+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:31:57.703+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:31:57.791+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:31:57.813+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:31:57.807+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:31:57.814+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:31:57.832+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.133 seconds
[2025-07-07T22:32:28.168+0000] {processor.py:161} INFO - Started process (PID=441) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:32:28.170+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:32:28.170+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:32:28.170+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:32:28.282+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:32:28.299+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:32:28.293+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:32:28.299+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:32:28.315+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.149 seconds
[2025-07-07T22:46:49.434+0000] {processor.py:161} INFO - Started process (PID=74) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:46:49.435+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:46:49.436+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:46:49.436+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:46:49.498+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:46:49.515+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:46:49.513+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:46:49.516+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:46:49.528+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.096 seconds
[2025-07-07T22:47:19.714+0000] {processor.py:161} INFO - Started process (PID=82) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:47:19.714+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:47:19.715+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:47:19.715+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:47:19.769+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:47:19.829+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:47:19.818+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:47:19.830+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:47:19.851+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.140 seconds
[2025-07-07T22:47:50.024+0000] {processor.py:161} INFO - Started process (PID=90) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:47:50.026+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:47:50.027+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:47:50.027+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:47:50.127+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:47:50.164+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:47:50.155+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:47:50.166+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:47:50.181+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.160 seconds
[2025-07-07T22:48:20.372+0000] {processor.py:161} INFO - Started process (PID=98) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:48:20.373+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:48:20.374+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:48:20.374+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:48:20.453+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:48:20.466+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:48:20.465+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:48:20.467+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:48:20.483+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.115 seconds
[2025-07-07T22:48:50.758+0000] {processor.py:161} INFO - Started process (PID=106) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:48:50.759+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:48:50.761+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:48:50.761+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:48:50.916+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:48:50.972+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:48:50.960+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:48:50.974+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:48:51.001+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.246 seconds
[2025-07-07T22:49:21.260+0000] {processor.py:161} INFO - Started process (PID=114) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:49:21.261+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:49:21.262+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:49:21.262+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:49:21.365+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:49:21.397+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:49:21.390+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:49:21.398+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:49:21.413+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.156 seconds
[2025-07-07T22:49:51.526+0000] {processor.py:161} INFO - Started process (PID=122) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:49:51.527+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:49:51.528+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:49:51.528+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:49:51.587+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:49:51.601+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:49:51.599+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 14, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:49:51.602+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:49:51.625+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.102 seconds
[2025-07-07T22:50:21.827+0000] {processor.py:161} INFO - Started process (PID=130) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:50:21.828+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:50:21.828+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:50:21.828+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:50:21.895+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:50:21.911+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:50:21.909+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 12, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 19, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:50:21.911+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:50:21.928+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.103 seconds
[2025-07-07T22:50:31.006+0000] {processor.py:161} INFO - Started process (PID=132) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:50:31.008+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:50:31.010+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:50:31.010+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:50:31.178+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:50:31.191+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:50:31.190+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 14, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 19, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:50:31.192+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:50:31.206+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.208 seconds
[2025-07-07T22:50:36.108+0000] {processor.py:161} INFO - Started process (PID=134) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:50:36.109+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:50:36.110+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:50:36.110+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:50:36.181+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:50:36.204+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:50:36.196+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 13, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 19, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:50:36.205+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:50:36.222+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.116 seconds
[2025-07-07T22:50:37.089+0000] {processor.py:161} INFO - Started process (PID=136) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:50:37.090+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:50:37.091+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:50:37.091+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:50:37.144+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:50:37.193+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:50:37.180+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 14, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 19, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:50:37.195+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:50:37.212+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.125 seconds
[2025-07-07T22:50:38.142+0000] {processor.py:161} INFO - Started process (PID=138) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:50:38.145+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:50:38.146+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:50:38.146+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:50:38.322+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:50:38.375+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:50:38.372+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 15, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 19, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:50:38.376+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:50:38.390+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.251 seconds
[2025-07-07T22:50:39.486+0000] {processor.py:161} INFO - Started process (PID=140) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:50:39.488+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:50:39.489+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:50:39.489+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:50:39.609+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:50:39.631+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:50:39.623+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 16, in <module>
    from Postgres_ETL import *
  File "/opt/airflow/dags/Postgres_ETL.py", line 19, in <module>
    spark = SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 97, in launch_gateway
    proc = Popen(command, **popen_kwargs)
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/spark/./bin/spark-submit'
[2025-07-07T22:50:39.631+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:50:39.645+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 0.161 seconds
[2025-07-07T22:50:44.544+0000] {processor.py:161} INFO - Started process (PID=142) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:50:44.545+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:50:44.546+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:50:44.546+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:50:44.630+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:50:46.297+0000] {processor.py:840} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:50:46.428+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:50:46.428+0000] {override.py:1769} INFO - Created Permission View: can delete on DAG:etl_pipeline
[2025-07-07T22:50:46.436+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:50:46.436+0000] {override.py:1769} INFO - Created Permission View: can edit on DAG:etl_pipeline
[2025-07-07T22:50:46.441+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:50:46.441+0000] {override.py:1769} INFO - Created Permission View: can read on DAG:etl_pipeline
[2025-07-07T22:50:46.442+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:50:46.442+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-07-07T22:50:46.449+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:50:46.449+0000] {dag.py:3058} INFO - Creating ORM DAG for etl_pipeline
[2025-07-07T22:50:46.457+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:50:46.456+0000] {dag.py:3823} INFO - Setting next_dagrun for etl_pipeline to 2025-07-06 00:00:00+00:00, run_after=2025-07-07 00:00:00+00:00
[2025-07-07T22:50:46.471+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 1.930 seconds
[2025-07-07T22:50:48.582+0000] {processor.py:161} INFO - Started process (PID=277) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:50:48.583+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:50:48.584+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:50:48.584+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:50:48.644+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:50:50.410+0000] {processor.py:840} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:50:50.420+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:50:50.420+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-07-07T22:50:50.437+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:50:50.437+0000] {dag.py:3823} INFO - Setting next_dagrun for etl_pipeline to 2025-07-06 00:00:00+00:00, run_after=2025-07-07 00:00:00+00:00
[2025-07-07T22:50:50.451+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 1.875 seconds
[2025-07-07T22:50:53.546+0000] {processor.py:161} INFO - Started process (PID=405) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:50:53.548+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:50:53.549+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:50:53.549+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:50:53.617+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:50:55.383+0000] {processor.py:840} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:50:55.392+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:50:55.392+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-07-07T22:50:55.409+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:50:55.409+0000] {dag.py:3823} INFO - Setting next_dagrun for etl_pipeline to 2025-07-06 00:00:00+00:00, run_after=2025-07-07 00:00:00+00:00
[2025-07-07T22:50:55.440+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 1.898 seconds
[2025-07-07T22:51:57.632+0000] {processor.py:161} INFO - Started process (PID=73) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:51:57.633+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:51:57.634+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:51:57.634+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:51:57.697+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:51:59.450+0000] {processor.py:840} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:51:59.479+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:51:59.479+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-07-07T22:51:59.493+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:51:59.493+0000] {dag.py:3823} INFO - Setting next_dagrun for etl_pipeline to 2025-07-06 00:00:00+00:00, run_after=2025-07-07 00:00:00+00:00
[2025-07-07T22:51:59.623+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 1.993 seconds
[2025-07-07T22:52:29.893+0000] {processor.py:161} INFO - Started process (PID=207) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:52:29.893+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:52:29.894+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:52:29.894+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:52:29.943+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:52:31.776+0000] {processor.py:840} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:52:31.795+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:52:31.794+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-07-07T22:52:31.810+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:52:31.810+0000] {dag.py:3823} INFO - Setting next_dagrun for etl_pipeline to 2025-07-06 00:00:00+00:00, run_after=2025-07-07 00:00:00+00:00
[2025-07-07T22:52:31.826+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 1.936 seconds
[2025-07-07T22:53:02.090+0000] {processor.py:161} INFO - Started process (PID=522) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:53:02.090+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:53:02.091+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:53:02.091+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:53:02.140+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:53:03.784+0000] {processor.py:840} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:53:03.802+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:53:03.802+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-07-07T22:53:03.818+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:53:03.817+0000] {dag.py:3823} INFO - Setting next_dagrun for etl_pipeline to 2025-07-07 00:00:00+00:00, run_after=2025-07-08 00:00:00+00:00
[2025-07-07T22:53:03.831+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 1.744 seconds
[2025-07-07T22:53:34.168+0000] {processor.py:161} INFO - Started process (PID=655) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:53:34.171+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:53:34.173+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:53:34.173+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:53:34.324+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:53:36.019+0000] {processor.py:840} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:53:36.037+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:53:36.037+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-07-07T22:53:36.052+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:53:36.052+0000] {dag.py:3823} INFO - Setting next_dagrun for etl_pipeline to 2025-07-07 00:00:00+00:00, run_after=2025-07-08 00:00:00+00:00
[2025-07-07T22:53:36.065+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 1.899 seconds
[2025-07-07T22:54:06.426+0000] {processor.py:161} INFO - Started process (PID=788) to work on /opt/airflow/dags/dags.py
[2025-07-07T22:54:06.427+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2025-07-07T22:54:06.428+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:54:06.428+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2025-07-07T22:54:06.501+0000] {logging_mixin.py:188} INFO - PySpark está disponível
[2025-07-07T22:54:08.279+0000] {processor.py:840} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/dags.py
[2025-07-07T22:54:08.296+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:54:08.296+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-07-07T22:54:08.312+0000] {logging_mixin.py:188} INFO - [2025-07-07T22:54:08.312+0000] {dag.py:3823} INFO - Setting next_dagrun for etl_pipeline to 2025-07-07 00:00:00+00:00, run_after=2025-07-08 00:00:00+00:00
[2025-07-07T22:54:08.334+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/dags.py took 1.910 seconds
